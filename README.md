# DasebigdataAssignmentGroup32
分布式系统小组作业

## 实验结果与分析
本部分基于实际实验数据，重点从是否使用Combiner、不同数据倾斜度两个维度，通过定量分析和可视化图表（图2、图3）验证Combiner对MapReduce作业性能的影响。

### 1. 数据指标整理
以下为16组sum实验的核心指标原始数据：

### 2. Combiner 对 Shuffle 数据量与执行时间的影响分析
**核心结论**：Combiner 通过 Map 端局部聚合，显著减少 Shuffle 数据传输量，进而缩短作业执行时间，且效果随数据量和倾斜度提升而增强。

具体分析如下：

**图 2-1：Shuffle 数据量对比分析**中可发现，Combiner 可使 Shuffle 数据量减少 67.86%-100%，优化效果随数据量和倾斜度提升呈递增趋势。其中不同场景的削减效果如下：

均匀分布场景：25MB 减少 67.86%、50MB 减少 67.90%、100MB 减少 91.52%，数据量越大优化越显著。

60% 倾斜场景：25MB 减少 76.53%、50MB 减少 76.58%、100MB 减少 99.99%，100MB 数据接近完全削减（184.07MB→0.01MB）。

90% 倾斜场景：100MB 和 200MB 均减少 100%，从 195.47MB/390.95MB 降至 0.01MB/0.02MB，达到优化上限，说明极端场景下效果最显著。

分析原理：

Shuffle 阶段是 MapReduce 的性能瓶颈（涉及磁盘 I/O 和网络传输），Combiner 在 Map 端提前聚合相同 key 数据，从源头减少传输量。

倾斜数据中重复 key 占比高，Combiner 的聚合效率更高，因此倾斜度越高，Shuffle 削减效果越明显。

- **均衡数据集**
- 
- **图 2-2：执行时间对比分析**中可发现，Combiner 可使作业执行时间缩短 13.33%-48.15%，大数据量 + 高倾斜场景优化幅度最大。其中：

  - 中小数据量（25-50MB）：优化幅度 13.33%-26.32%，60% 倾斜 50MB 数据从 38 秒降至 28 秒，缩短 26.32%。

  - 大数据量（100-200MB）：优化幅度 13.85%-48.15%，60% 倾斜 100MB 数据从 108 秒降至 56 秒，缩短 48.15%（优化幅度最大）。

  - 90% 倾斜 200MB：从 112 秒降至 60 秒，缩短 46.43%，在超大数据量下仍保持高优化率。

- 分析原理：时间优化的双重驱动

  - 直接驱动：Shuffle 数据量减少降低网络传输时间，尤其在集群环境中网络带宽有限时效果更突出。

  - 间接驱动：Reduce 端输入记录数大幅减少（后续图 3-2 分析），降低 Reduce 的排序和计算压力，进一步缩短整体时间。


### 3.不同数据倾斜度下 Combiner 的性能差异分析

**核心结论**：数据倾斜度越高，Combiner 的性能提升效果越明显，主要体现在 Reduce 输入记录数的削减和时间优化幅度的提升。

具体分析如下：

**图 3-1：Shuffle 减少百分比趋势分析**说明，数据倾斜度与 Combiner 优化效果呈正相关，90% 倾斜是优化效果的 “饱和点”。

趋势特征：

相同数据量下：倾斜度每提升 30%，Shuffle 减少率平均提升 8-15 个百分点。如 25MB 数据：均匀分布 67.86% < 60% 倾斜 76.53%，提升 8.67 个百分点。

相同倾斜度下：均匀分布数据量从 25MB→100MB，减少率提升 23.66 个百分点；高倾斜场景（60%+）数据量影响较小，90% 倾斜保持 100% 减少率。

实践指导意义：

对均匀分布数据，建议优先在 100MB 以上场景开启 Combiner，优化投入产出比更高。

对倾斜度≥60% 的数据，无论数据量大小，开启 Combiner 均可获得显著优化效果，建议强制启用。

**图 3-2：Reduce 输入记录数对比分析**说明，Combiner 可使 Reduce 输入记录数减少 67.86%-100%，彻底解决 Reduce 端数据热点问题。
