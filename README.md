<<<<<<< Updated upstream
<<<<<<< Updated upstream
# DasebigdataAssignmentGroup32
åˆ†å¸ƒå¼ç³»ç»Ÿå°ç»„ä½œä¸š
=======
=======
>>>>>>> Stashed changes
# ğŸ“˜ **å®éªŒæŠ¥å‘Šï¼šMapReduce Combiner æœºåˆ¶åˆ†æ**

### **ç ”ç©¶ç›®çš„ï¼šæ¢ç©¶MapReduceä¸­Combinerå¯¹ä½œä¸šæ€§èƒ½çš„å½±å“**

------

# **1. å®éªŒç¯å¢ƒ**

## **1.1 ç¡¬ä»¶ç¯å¢ƒï¼ˆé›†ç¾¤é…ç½®ï¼‰**

æœ¬æ¬¡å®éªŒåŸºäºé˜¿é‡Œäº‘ ECS è‡ªå»º Hadoop é›†ç¾¤å®Œæˆï¼Œå…±åŒ…å« **4 ä¸ªèŠ‚ç‚¹**ï¼š1 ä¸ª Master èŠ‚ç‚¹ä¸ 3 ä¸ª Worker èŠ‚ç‚¹ã€‚é›†ç¾¤é‡‡ç”¨ Hadoop **3.4.2** ç‰ˆæœ¬ï¼Œç»Ÿä¸€ä½¿ç”¨ **Linux (Ubuntu 20.04)** æ“ä½œç³»ç»Ÿï¼Œå¹¶é€šè¿‡ YARN ä½œä¸ºèµ„æºç®¡ç†ä¸ä»»åŠ¡è°ƒåº¦æ¡†æ¶ã€‚

| èŠ‚ç‚¹    | è§’è‰²                       | vCPU | å†…å­˜ | å­˜å‚¨ç±»å‹ | å¸¦å®½     |
| ------- | -------------------------- | ---- | ---- | -------- | -------- |
| master  | NameNode + ResourceManager | 2 æ ¸ | 2GB  | SSD      | 100 Mbps |
| worker1 | DataNode + NodeManager     | 2 æ ¸ | 2GB  | SSD      | 100 Mbps |
| worker2 | DataNode + NodeManager     | 2 æ ¸ | 2GB  | SSD      | 100 Mbps |
| worker3 | DataNode + NodeManager     | 2 æ ¸ | 2 GB | SSD      | 100 Mbps |

## **1.2 è½¯ä»¶ç¯å¢ƒ**

| ç»„ä»¶   | ç‰ˆæœ¬              |
| ------ | ----------------- |
| OS     | Ubuntu 22.04 64ä½ |
| JDK    | JDK 1.8.0_472     |
| Hadoop | Hadoop 3.4.2      |
| SSH    | Xshell 8          |

------

## 1.3 HadoopæœåŠ¡è¿›ç¨‹

(1)masterèŠ‚ç‚¹
![](image/comfiguration/jps/master_jps.png)


(2)worker1
![](image/comfiguration/jps/worker1_jps.png)


(3)worker2
![](image/comfiguration/jps/worker2_jps.png)



(4)worker3
![](image/comfiguration/jps/worker3_jps.png)






## 1.4 é›†ç¾¤ç«¯å£

| æœåŠ¡                 | ç«¯å£  | ä½œç”¨                        |
| -------------------- | ----- | --------------------------- |
| HDFS NameNode        | 9870  | æŸ¥çœ‹ HDFS æ–‡ä»¶ç³»ç»ŸçŠ¶æ€      |
| YARN ResourceManager | 8088  | æŸ¥çœ‹ Application æ‰§è¡Œæƒ…å†µ   |
| JobHistory Server    | 19888 | æŸ¥çœ‹ MapReduce è¯¦ç»†å†å²ä¿¡æ¯ |

(1)Web UI 9870ç«¯å£
![](image/comfiguration/9870.png)
(2)Web UI 8088ç«¯å£
![](image/comfiguration/8088.png)
## 1.5 HDFSå­˜å‚¨ç»“æ„
![](image/comfiguration/jps/hdfs_data.png)


## 1.6 é›†ç¾¤éƒ¨ç½²æ–¹å¼

- é‡‡ç”¨ é˜¿é‡Œäº‘ ECS + VPC å†…ç½‘ éƒ¨ç½²

- é…ç½® SSH å…å¯†é€šä¿¡ï¼Œå®ç°è‡ªåŠ¨å¯åŠ¨ Hadoop é›†ç¾¤

- æ‰€æœ‰é…ç½®ï¼ˆcore-site.xml, hdfs-site.xml, yarn-site.xml, mapred-site.xmlï¼‰ä¿æŒä¸€è‡´

#  2.å®éªŒè´Ÿè½½

## 2.1æ•°æ®é›†

|     æ•°æ®é›†åç§°      | ä¸å‡è¡¡ç¨‹åº¦ | å¤§å°  |
| :-----------------: | :--------: | :---: |
|  uniform_100MB.txt  |     0%     | 100MB |
|  uniform_50MB.txt   |     0%     | 50MB  |
|  uniform_25MB.txt   |     0%     | 25MB  |
|  skew60_100MB.txt   |    60%     | 100MB |
|   skew60_50MB.txt   |    60%     | 50MB  |
|  skew_60_25MB.txt   |    60%     | 25MB  |
| extreme90_100MB.txt |    90%     | 100MB |
| extreme90_200MB.txt |    90%     | 200MB |
|      avg_50MB       |            | 50MB  |
<<<<<<< Updated upstream

æœ¬å®éªŒä¸€å…±æ„é€ äº†9ä¸ªæ•°æ®é›†ã€‚å…¶ä¸­ï¼Œ8ä¸ªæ•°æ®é›†ç”¨äºç ”ç©¶åœ¨ä¸åŒè§„æ¨¡å’Œkeyåˆ†å¸ƒä¸‹Combinerçš„æ•ˆæœï¼š

- **å‡è¡¡æ•°æ®é›†**ï¼ˆkey å‡åŒ€åˆ†å¸ƒï¼‰ï¼š
  - 25MBã€50MBã€100MB ä¸‰ä¸ªè§„æ¨¡ã€‚
  - å„ä¸ª key å‡ºç°æ¬¡æ•°å¤§è‡´ç›¸åŒï¼Œæ²¡æœ‰æ˜æ˜¾çƒ­ç‚¹ keyã€‚
- **å€¾æ–œæ•°æ®é›†ï¼ˆ60%ï¼‰**ï¼š
  - 25MBã€50MBã€100MB ä¸‰ä¸ªè§„æ¨¡ã€‚
  - çº¦ 60% çš„è®°å½•é›†ä¸­åœ¨å°‘æ•°çƒ­ç‚¹ key ä¸Šï¼Œå…¶ä½™è®°å½•åˆ†å¸ƒåœ¨å…¶ä»– key ä¸Šã€‚
- **å€¾æ–œæ•°æ®é›†ï¼ˆ90%ï¼‰**ï¼š
  - 100MBã€200MB ä¸¤ä¸ªè§„æ¨¡ã€‚
  - çº¦ 90% çš„è®°å½•é›†ä¸­åœ¨æ›´å°‘æ•°çš„çƒ­ç‚¹ key ä¸Šï¼Œæ•°æ®å€¾æ–œæ›´ä¸¥é‡ã€‚

è¿™8ä¸ªæ•°æ®é›†ç”¨äºæ±‚å’Œä»»åŠ¡ï¼Œæ¯æ¡æ•°æ®çš„è®°å½•æ ¼å¼ä¸ºï¼škey valueï¼Œå…¶ä¸­keyä¸ºintå‹ï¼Œvalueå€¼å‡ä¸º1ã€‚

avg_50MBæ•°æ®é›†ç”¨äºæ±‚å¹³å‡å€¼çš„ä»»åŠ¡ï¼Œkeyå€¼å‡ä¸º1ï¼Œvalueå€¼ä¸ºintå‹ã€‚

## 2.2 ä»»åŠ¡æè¿°

### ä»»åŠ¡ä¸€ï¼škey-valueæ±‚å’Œï¼ˆæœ‰æ— Combinerï¼‰

ä»»åŠ¡ç›®æ ‡æ˜¯å¯¹è¾“å…¥æ•°æ®ä¸­çš„æ‰€æœ‰è®°å½•ï¼ŒæŒ‰ç…§keyè¿›è¡Œvalueçš„æ±‚å’Œï¼Œè¾“å‡ºæ¯ä¸ªkeyçš„æ€»å’Œç»“æœã€‚

åœ¨Mapé˜¶æ®µï¼Œå¯¹äºè¾“å…¥çš„æ–‡æœ¬è¡Œâ€œkey valueâ€ï¼Œä¼šè§£æå‡ºå­—ç¬¦ä¸²keyå’Œæ•´æ•°valueç„¶åè¾“å‡ºä¸­é—´é”®å€¼å¯¹ï¼ˆkey,value)ã€‚åœ¨Combineré˜¶æ®µï¼Œä¸Reducerä¸€æ ·ï¼Œä¼šåœ¨Mapä»»åŠ¡çš„è¾“å‡ºé˜¶æ®µå¯¹ç›¸åŒkeyçš„valueè¿›è¡Œå±€éƒ¨æ±‚å’Œï¼Œä»¥æ­¤æ¥ä»‹ç»å‘å¾€ä¸‹æ¸¸çš„ä¸­é—´é”®å€¼å¯¹çš„æ•°é‡ï¼Œä»è€Œå‡å°‘ç½‘ç»œä¼ è¾“å’ŒReduceç«¯çš„è´Ÿè½½ã€‚åœ¨Reduceæç«¯ï¼ŒReducerä¼šæ¥æ”¶æ¥è‡ªå¤šä¸ªMap/Combinerçš„(key,valueSum)å¯¹ï¼Œå®Œæˆå…¨å±€æ±‚å’Œã€‚

å®éªŒè®¾è®¡ä¸Šï¼Œæˆ‘ä»¬å¯¹æ¯ä¸ªæ•°æ®é›†éƒ½è¿›è¡Œä¸¤æ¬¡å®éªŒã€‚å½“å…³é—­Combineræ—¶ï¼ŒMapçš„è¾“å‡ºä¼šç›´æ¥è¿›å…¥Shuffleé˜¶æ®µï¼›å½“å¼€å¯Combineræ—¶ï¼Œä¼šåœ¨MapèŠ‚ç‚¹è¿›è¡Œå±€éƒ¨èšåˆã€‚é€šè¿‡åœ¨ä¸åŒå€¾æ–œåº¦çš„æ•°æ®é›†ä»¥åŠä¸åŒå¤§å°çš„æ•°æ®é›†ä¸Šè¿›è¡Œå®éªŒï¼Œæ¥æ¢ç©¶æœ‰æ— Combinerå¯¹MapReduceä½œä¸šæ€§èƒ½çš„å½±å“ã€‚

### ä»»åŠ¡äºŒï¼šæŒ‰keyæ±‚å¹³å‡å€¼

ä»»åŠ¡ç›®æ ‡æ˜¯å¯¹50MBçš„å‡è¡¡æ•°æ®é›†keyè®¡ç®—valueçš„å¹³å‡å€¼ã€‚

ç›´æ¥åœ¨Combinerä¸­å¯¹valueæ±‚å¹³å‡å€¼ï¼Œç„¶åå†åœ¨Reducerä¸­å¯¹è¿™äº›â€œå±€éƒ¨å¹³å‡å€¼â€å†æ±‚å¹³å‡ä¼šå¾—å‡ºé”™è¯¯çš„ç»“æœï¼Œå› ä¸ºâ€œå¹³å‡å€¼â€æœ¬èº«ä¸æ»¡è¶³ç®€å•çš„ç»“åˆå¾‹ã€‚æ‰€ä»¥åœ¨æ±‚å¹³å‡å€¼æ—¶ï¼Œéœ€è¦æ”¹å˜MapReduceçš„å¹³å‡å€¼è®¡ç®—æ¨¡å¼ï¼šå°†å¹³å‡å€¼æ‹†åˆ†ä¸ºsumå’Œcountä¸¤ä¸ªéƒ¨åˆ†ã€‚è¿™ä¸¤ä¸ªéƒ¨åˆ†å¯ä»¥è¿›è¡Œå¯ç»“åˆçš„åŠ æ³•æ“ä½œï¼Œå¾—å‡ºæ­£ç¡®çš„ç»“æœã€‚

åœ¨Mapé˜¶æ®µå¯¹äºè¾“å…¥çš„æ¯ä¸€æ¡è®°å½•ï¼Œè¾“å‡º(sum,value)å’Œï¼ˆcount,1)ï¼Œè¾“å…¥Combineré˜¶æ®µï¼Œä¼šå¯¹sumå’Œcountè¿›è¡Œåˆ†åˆ«æ±‚å’Œï¼Œè¿™æ—¶Combineråªåšäº†åŠ æ³•ï¼Œæ»¡è¶³äº†ç»“åˆå¾‹å’Œäº¤æ¢å¾‹ï¼Œä¸ä¼šå½±å“æœ€ç»ˆçš„ç»“æœï¼ŒåŒæ—¶ä¹Ÿå¤§å¹…åº¦å‡å°‘äº†ä¼ è¾“åˆ°Reducerçš„ä¸­é—´é”®å€¼å¯¹æ•°é‡ã€‚Reduceræœ€åå¯¹å¤šä¸ªMap/Combinerè¾“å‡ºçš„å€¼è¿›è¡Œç´¯åŠ ï¼Œå¾—åˆ°å…¨å±€çš„(sum,count)å¹¶æ±‚å‡ºå¹³å‡å€¼ã€‚

è¯¥ä»»åŠ¡åªåœ¨avg_50MBä¸€ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œé€šè¿‡å¯¹æ¯”åœ¨ä¸ä½¿ç”¨Combinerã€ä½¿ç”¨é”™è¯¯çš„æ¨¡å¼ä»¥åŠä½¿ç”¨æ­£ç¡®çš„æ”¯æŒCombinerçš„æ¨¡å¼è¿™ä¸‰ç§æƒ…å†µä¸‹çš„ç»“æœï¼Œæ¢ç©¶Combineré€‚åˆä½¿ç”¨çš„ä»»åŠ¡åœºæ™¯ï¼Œè®¾è®¡å‡ºé€‚åˆCombinerçš„èšåˆé€»è¾‘ã€‚

__é€šè¿‡ä¸Šè¿°ä¸¤ç±»å·¥ä½œè´Ÿè½½ä¸å¤šç»„æ•°æ®é›†çš„ç»“åˆï¼Œæœ¬å®éªŒå¯ä»¥ç³»ç»Ÿå›ç­”ä»¥ä¸‹é—®é¢˜ï¼š__

1.Combineræ˜¯å¦èƒ½å¤Ÿæœ‰æ•ˆå‡å°‘Shuffleé˜¶æ®µçš„æ•°æ®é‡ï¼Ÿ

2.åœ¨ä¸åŒå€¾æ–œåº¦çš„æ•°æ®é›†ä¸Šï¼ŒCombinerçš„æ€§èƒ½æå‡æœ‰ä½•å·®å¼‚ï¼Ÿ

3.æ˜¯å¦æ‰€æœ‰åœºæ™¯éƒ½é€‚åˆä½¿ç”¨Combinerï¼Ÿ

> [!IMPORTANT]
>
> ### ä¸ºä»€ä¹ˆkey-value æ±‚å’Œä»»åŠ¡é€‚åˆç”¨ combiner
>
> å› ä¸ºCombineræœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªåœ¨Mapç«¯çš„â€œè¿·ä½ Reducerâ€ï¼Œå®ƒå¿…é¡»èƒ½å¤Ÿä»¥ä»»æ„é¡ºåºã€ä»»æ„åˆ†ç»„æ–¹å¼å¤„ç†Mapè¾“å‡ºçš„ä¸­é—´ç»“æœï¼Œè€Œä¸å½±å“æœ€ç»ˆç»“æœçš„æ­£ç¡®å®šæ€§ï¼Œè€Œç»“åˆå¾‹å’Œäº¤æ¢å¾‹æ­£æ˜¯ä¿è¯è¿™ç§â€œä»»æ„æ€§â€ä¸ä¼šå¯¼è‡´é”™è¯¯çš„å…³é”®å±æ€§ã€‚
>
> Combinerçš„ä½œç”¨
>
> ã€€ã€€åœ¨MapReduceä¸­ï¼ŒCombinerçš„ä½œç”¨æ˜¯åœ¨Mapä»»åŠ¡å®Œæˆåï¼Œåœ¨æœ¬åœ°å…ˆå¯¹è¾“å‡ºçš„<key, value>å¯¹è¿›è¡Œä¸€æ¬¡åˆå¹¶ï¼Œç„¶åå†å°†ç»“æœé€šè¿‡ç½‘ç»œå‘é€ç»™Reducerã€‚
>
> ã€€ã€€ç›®çš„ï¼šå‡å°‘Mapå’ŒReduceä»»åŠ¡ä¹‹é—´çš„ç½‘ç»œä¼ è¾“æ•°æ®é‡ï¼Œæå‡æ•´ä½“ä½œä¸šæ€§èƒ½ã€‚
>
> ã€€ã€€è¿è¡Œä½ç½®ï¼šå®ƒåœ¨æ¯ä¸ªMapä»»åŠ¡èŠ‚ç‚¹ä¸Šè¿è¡Œï¼Œå¤„ç†è¯¥Mapä»»åŠ¡è‡ªå·±äº§ç”Ÿçš„ä¸­é—´ç»“æœã€‚
>
> å› ä¸ºåŠ æ³•æ»¡è¶³ç»“åˆå¾‹å’Œäº¤æ¢å¾‹ï¼Œè¿™ä¸¤ä¸ªæ€§è´¨ä¿è¯äº†æ— è®ºæ•°æ®æ˜¯å¦‚ä½•åˆ†å¸ƒçš„ï¼Œåªè¦æœ€ç»ˆçš„æ“ä½œæ˜¯åŠ æ³•ï¼Œç»“æœå°†å§‹ç»ˆæ˜¯ä¸€æ ·çš„ã€‚è¿™æ­£æ˜¯ä½¿ç”¨combineræ—¶çš„æ ¸å¿ƒä¼˜åŠ¿ã€‚
>
> åœ¨ MapReduce ä¸­ï¼Œæ•°æ®ä» Map é˜¶æ®µä¼ è¾“åˆ° Reduce é˜¶æ®µæ—¶ï¼Œä¼ è¾“çš„ä¸­é—´æ•°æ®é‡å¯èƒ½ä¼šéå¸¸å¤§ã€‚é€šè¿‡ä½¿ç”¨ combinerï¼Œæˆ‘ä»¬å¯ä»¥åœ¨Map ä»»åŠ¡çš„èŠ‚ç‚¹ä¸Šå¯¹ç›¸åŒçš„ key è¿›è¡Œå±€éƒ¨æ±‚å’Œï¼Œç„¶åå°†æ±‚å’Œç»“æœä¼ é€’ç»™ Reducerã€‚è¿™æ ·å¯ä»¥æ˜¾è‘—å‡å°‘éœ€è¦ä¼ è¾“åˆ°Reducer çš„æ•°æ®é‡ã€‚
>
> ç”±äºåŠ æ³•çš„ç»“åˆå¾‹å’Œäº¤æ¢å¾‹ï¼Œå±€éƒ¨åˆå¹¶çš„é¡ºåºä¸ä¼šå½±å“æœ€ç»ˆç»“æœã€‚å³ä½¿ä¸åŒçš„ Map ä»»åŠ¡åœ¨ä¸åŒçš„èŠ‚ç‚¹ä¸Šå¹¶è¡Œè¿è¡Œï¼ŒReducer ä»ç„¶èƒ½å¤Ÿå¾—åˆ°æ­£ç¡®çš„æ€»å’Œï¼Œå› ä¸ºå„ä¸ªèŠ‚ç‚¹ä¸Šçš„å±€éƒ¨ç»“æœä¼šè¢«åˆå¹¶æˆæœ€ç»ˆçš„æ­£ç¡®ç»“æœã€‚è¿™ä¿è¯äº†åˆ†å¸ƒå¼è®¡ç®—ä¸­çš„ä¸€è‡´æ€§å’Œæ­£ç¡®æ€§ã€‚
>
> ä½¿ç”¨ combiner å¯ä»¥å‡å°‘ Reducer ç«¯çš„è®¡ç®—è´Ÿæ‹…ï¼Œå› ä¸ºå®ƒæ”¶åˆ°çš„æ•°æ®å·²ç»æ˜¯éƒ¨åˆ†åˆå¹¶è¿‡çš„ã€‚ä¾‹å¦‚ï¼ŒReducer ä¸éœ€è¦é‡å¤è®¡ç®—æ¯ä¸ª key çš„æ‰€æœ‰å€¼çš„å’Œï¼Œè€Œæ˜¯ç›´æ¥å¯¹å±€éƒ¨åˆå¹¶çš„ç»“æœè¿›è¡Œå¤„ç†ï¼Œè¿›ä¸€æ­¥æé«˜äº†è®¡ç®—æ•ˆç‡ã€‚



## 2.3 ç®€è¦æè¿°Java ä»£ç ç»“æ„ï¼ˆåŒ…åã€ç±»åã€ä¸»è¦å‡½æ•°ï¼‰

### ï¼ˆ1ï¼‰`SumWithCombiner.java` ä»£ç ç»“æ„

åŒ…åå’Œå¯¼å…¥è¯­å¥ï¼š

å¼•å…¥äº†å¿…è¦çš„ Hadoop ç±»å’Œ IO åº“ã€‚

```java
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.*;
import org.apache.hadoop.mapreduce.*;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
```

ä¸»ç±» `SumWithCombiner`ï¼š

è¿™æ˜¯æ•´ä¸ªç¨‹åºçš„æ ¸å¿ƒç±»ï¼ŒåŒ…å«äº† MapReduce ä»»åŠ¡çš„å®ç°ã€‚

Mapper ç±» `SumMapper`ï¼š

`SumMapper` ç»§æ‰¿è‡ª `Mapper<LongWritable, Text, Text, IntWritable>`ï¼Œè´Ÿè´£å¤„ç†è¾“å…¥æ•°æ®å¹¶ç”Ÿæˆ key-value å¯¹ã€‚

`map()` æ–¹æ³•ï¼šè¾“å…¥æ¯ä¸€è¡Œæ•°æ®ï¼ˆ`LongWritable` å’Œ `Text`ï¼‰ï¼Œå°†å…¶æ‹†åˆ†åç”Ÿæˆç›¸åº”çš„ key å’Œ valueï¼ˆ`Text` å’Œ `IntWritable`ï¼‰ã€‚

```java
public static class SumMapper extends Mapper<LongWritable, Text, Text, IntWritable> {
    private Text outKey = new Text();
    private IntWritable outValue = new IntWritable();
    
    protected void map(LongWritable key, Text value, Context context) {
        // æŒ‰ç©ºæ ¼åˆ†å‰²è¾“å…¥è¡Œ
        // æå–ç¬¬ä¸€ä¸ªå­—æ®µä½œä¸ºkeyï¼Œç¬¬äºŒä¸ªå­—æ®µä½œä¸ºvalue
        // è¾“å‡º: (key, value)
    }
}
```

Reducer ç±» `SumReducer`ï¼š

`SumReducer` ç»§æ‰¿è‡ª `Reducer<Text, IntWritable, Text, IntWritable>`ï¼Œè´Ÿè´£å¯¹ `Mapper` è¾“å‡ºçš„ key-value å¯¹è¿›è¡Œèšåˆï¼Œè®¡ç®—æ¯ä¸ª key çš„æ€»å’Œã€‚

```java
public static class SumReducer extends Reducer<Text, IntWritable, Text, IntWritable> {
    protected void reduce(Text key, Iterable<IntWritable> values, Context context) {
        // å¯¹ç›¸åŒkeyçš„æ‰€æœ‰valueè¿›è¡Œæ±‚å’Œ
        // è¾“å‡º: (key, sum)
    }
}
```

Job é…ç½®ï¼š

åœ¨ `main()` æ–¹æ³•ä¸­ï¼Œé…ç½® Hadoop çš„ Jobï¼Œè®¾ç½®è¾“å…¥è¾“å‡ºè·¯å¾„ã€Mapperã€Reducer ç±»ï¼Œå¹¶æŒ‡å®šè¾“å‡ºçš„æ•°æ®ç±»å‹ï¼Œè®¾ç½® `Combiner`ï¼ˆæ­¤ä»£ç ä¸­é€šè¿‡ `job.setCombinerClass(SumReducer.class)` è®¾ç½®äº† `Combiner`ï¼‰ã€‚

```java
public static void main(String[] args) {
    // åˆ›å»ºJobå®ä¾‹
    Job job = Job.getInstance(conf, "Sum With Combiner");
    
    // è®¾ç½®Mapperå’ŒReducerç±»
    job.setMapperClass(SumMapper.class);
    job.setReducerClass(SumReducer.class);
    
    // å…³é”®ï¼šå¯ç”¨Combinerï¼Œç›´æ¥ä½¿ç”¨Reducerä½œä¸ºCombiner
    job.setCombinerClass(SumReducer.class);
    
    // è®¾ç½®è¾“å…¥è¾“å‡ºè·¯å¾„
    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
}
```



### ï¼ˆï¼’ï¼‰`SumNoCombiner.java` ä»£ç ç»“æ„

åŒ…åå’Œå¯¼å…¥è¯­å¥ï¼š

å¼•å…¥äº†å¿…è¦çš„ Hadoop ç±»å’Œ IO åº“ã€‚

```java
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.*;
import org.apache.hadoop.mapreduce.*;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
```

ä¸»ç±» `SumNoCombiner`ï¼š

è¿™æ˜¯æ•´ä¸ªç¨‹åºçš„æ ¸å¿ƒç±»ï¼ŒåŒ…å«äº† MapReduce ä»»åŠ¡çš„å®ç°ï¼Œæ²¡æœ‰ä½¿ç”¨ Combinerã€‚

Mapper ç±» `SumMapper`ï¼š

`SumMapper` ç»§æ‰¿è‡ª `Mapper<LongWritable, Text, Text, IntWritable>`ï¼Œä¸å‰ä¸€ä¸ªç‰ˆæœ¬ç›¸ä¼¼ï¼Œè´Ÿè´£è¾“å…¥æ•°æ®çš„å¤„ç†å¹¶è¾“å‡º key-value å¯¹ã€‚

```java
public static class SumMapper extends Mapper<LongWritable, Text, Text, IntWritable> {
    private Text outKey = new Text();
    private IntWritable outValue = new IntWritable();
    
    protected void map(LongWritable key, Text value, Context context) {
        // è¾“å…¥æ ¼å¼: "key value"
        // æŒ‰ç©ºæ ¼åˆ†å‰²è¾“å…¥è¡Œ
        // è¾“å‡º: (Text_key, IntWritable_value)
    }
}
```

Reducer ç±» `SumReducer`ï¼š

è´Ÿè´£å¯¹ `Mapper` è¾“å‡ºçš„ key-value å¯¹è¿›è¡Œåˆå¹¶æ“ä½œï¼Œè®¡ç®—æ¯ä¸ª key çš„æ€»å’Œã€‚

```java
public static class SumReducer extends Reducer<Text, IntWritable, Text, IntWritable> {
    protected void reduce(Text key, Iterable<IntWritable> values, Context context) {
        // å¯¹ç›¸åŒkeyçš„æ‰€æœ‰valuesè¿›è¡Œæ±‚å’Œ
        int sum = 0;
        for (IntWritable v : values) {
            sum += v.get();
        }
        // è¾“å‡º: (key, total_sum)
    }
}
```

Job é…ç½®ï¼š

åœ¨ `main()` æ–¹æ³•ä¸­ï¼Œé…ç½® Hadoop ä½œä¸šï¼Œè®¾ç½®è¾“å…¥è¾“å‡ºè·¯å¾„ã€Mapperã€Reducer ç±»ï¼Œå¹¶æŒ‡å®šè¾“å‡ºçš„æ•°æ®ç±»å‹ï¼Œæ²¡æœ‰ä½¿ç”¨ `Combiner`ï¼Œæ‰€æœ‰çš„åˆå¹¶å·¥ä½œç”± `Reducer` å®Œæˆã€‚

```java
public static void main(String[] args) {
    // åˆ›å»ºJobå®ä¾‹
    Job job = Job.getInstance(conf, "Sum No Combiner");
    
    // è®¾ç½®Mapperå’ŒReducerç±»
    job.setMapperClass(SumMapper.class);
    job.setReducerClass(SumReducer.class);
    
    // å…³é”®åŒºåˆ«ï¼šæ²¡æœ‰è®¾ç½®Combiner
    // job.setCombinerClass(...);  // æ­¤è¡Œç¼ºå¤±
    
    // è®¾ç½®è¾“å…¥è¾“å‡ºè·¯å¾„
    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
}
```



### ï¼ˆï¼“ï¼‰`AverageNoCombiner.java` ä»£ç ç»“æ„

åŒ…åå’Œå¯¼å…¥è¯­å¥ï¼š

ä»£ç é¦–å…ˆå¯¼å…¥äº† Hadoop å’Œç›¸å…³çš„ I/O ç±»ï¼Œè§ï¼ˆ1ï¼‰ã€‚

ä¸»ç±» `AverageNoCombiner`ï¼š

æ•´ä¸ªç¨‹åºçš„ä¸»ç±»ï¼Œç±»åä¸º `AverageNoCombiner`ï¼Œç”¨äºè®¡ç®—å¹³å‡å€¼ï¼ˆæ²¡æœ‰ä½¿ç”¨combinerï¼‰ã€‚

Mapper ç±» `AvgMapper`ï¼š

è¯¥ç±»ç»§æ‰¿è‡ª `Mapper<LongWritable, Text, Text, LongWritable>`ï¼Œç”¨äºå¤„ç†è¾“å…¥æ•°æ®å¹¶ç”Ÿæˆä¸­é—´è¾“å‡ºï¼Œä¸»è¦ä»»åŠ¡æ˜¯è§£æè¾“å…¥æ•°æ®ï¼Œå¹¶ç”Ÿæˆä¸¤ä¸ª key-value å¯¹`"sum"` å’Œæ€»å’Œï¼ˆ`LongWritable`ï¼‰ï¼Œ `"count"` å’Œè®¡æ•°ï¼ˆ`LongWritable`ï¼‰

`map()` æ–¹æ³•ï¼šè¯¥æ–¹æ³•è§£ææ¯è¡Œè¾“å…¥æ•°æ®ï¼Œæå–æ•°å€¼å¹¶åˆ†åˆ«è¾“å‡º sum å’Œ countã€‚

```java
public static class AvgMapper extends Mapper<LongWritable, Text, Text, LongWritable> {
    private final static Text SUM = new Text("sum");
    private final static Text COUNT = new Text("count");
    
    protected void map(LongWritable key, Text value, Context context) {
        // è¾“å…¥æ ¼å¼: "key value" (å¦‚ "1 39")
        // è¾“å‡ºä¸¤æ¡è®°å½•:
        // ("sum", æ•°å€¼)     - ç”¨äºç´¯åŠ æ€»å’Œ
        // ("count", 1)     - ç”¨äºè®¡æ•°
    }
}
```

Reducer ç±» `AvgReducer`ï¼š

`AvgReducer` ç±»å¯¹æ¥è‡ª Mapper çš„è¾“å‡ºè¿›è¡Œèšåˆï¼Œè®¡ç®—æ¯ä¸ª key å¯¹åº”çš„æ€»å’Œå’Œè®¡æ•°ï¼Œæœ€ç»ˆè®¡ç®—å‡ºå¹³å‡å€¼ï¼Œå®ƒå°†å¤„ç† `"sum"` å’Œ `"count"` çš„ç»“æœï¼Œå¹¶è®¡ç®—å¹³å‡å€¼ã€‚

```java
public static class AvgReducer extends Reducer<Text, LongWritable, Text, DoubleWritable> {
    long sum = 0;
    long count = 0;
    
    protected void reduce(Text key, Iterable<LongWritable> values, Context context) {
        // åˆ†åˆ«å¤„ç†"sum"å’Œ"count"é”®
        if (key.equals("sum")) {
            for (LongWritable val : values) sum += val.get();
        } else { // count
            for (LongWritable val : values) count += val.get();
        }
    }
    
    protected void cleanup(Context context) {
        // åœ¨æ‰€æœ‰reduceå®Œæˆåè®¡ç®—æœ€ç»ˆå¹³å‡å€¼
        double avg = (double) sum / count;
        context.write(new Text("Average"), new DoubleWritable(avg));
    }
}
```

Job é…ç½®ï¼š

åœ¨ `main()` æ–¹æ³•ä¸­ï¼Œé…ç½® Hadoop çš„ä½œä¸šï¼Œè®¾ç½®è¾“å…¥è¾“å‡ºè·¯å¾„ã€Mapper å’Œ Reducer ç±»ï¼Œå¹¶å®šä¹‰è¾“å‡ºæ•°æ®ç±»å‹ã€‚

 

```java
public static void main(String[] args) {
    Job job = Job.getInstance(conf, "average_no_combiner");
    
    job.setMapperClass(AvgMapper.class);
    job.setReducerClass(AvgReducer.class);
    
    // æ³¨æ„ï¼šæ²¡æœ‰è®¾ç½®Combiner
    // è¾“å‡ºç±»å‹ï¼šText, LongWritable (Mapperè¾“å‡ºç±»å‹)
    
    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
}
```



### ï¼ˆ4ï¼‰`AverageWithCombiner.java`ä»£ç ç»“æ„

åŒ…åå’Œå¯¼å…¥è¯­å¥ï¼š

ä»£ç é¦–å…ˆå¯¼å…¥äº† Hadoop å’Œç›¸å…³çš„ I/O ç±»

ä¸»ç±» `AverageWithCombiner`ï¼š

æ•´ä¸ªç¨‹åºçš„ä¸»ç±»ï¼Œç±»åä¸º `AverageWithCombiner`ï¼Œç”¨äºè®¡ç®—å¹³å‡å€¼ï¼Œå¹¶ä½¿ç”¨äº† combiner æ¥ä¼˜åŒ–æ€§èƒ½ã€‚

Mapper ç±» `AvgMapper`ï¼š

è¯¥ç±»ç»§æ‰¿è‡ª `Mapper<LongWritable, Text, Text, LongWritable>`ï¼Œè´Ÿè´£å¤„ç†è¾“å…¥æ•°æ®å¹¶ç”Ÿæˆä¸­é—´è¾“å‡ºï¼Œä¸»è¦ä»»åŠ¡æ˜¯è§£æè¾“å…¥æ•°æ®ï¼Œå¹¶ç”Ÿæˆä¸¤ä¸ª key-value å¯¹ï¼š`"sum"` å’Œæ€»å’Œï¼ˆ`LongWritable`ï¼‰å’Œ`"count"` å’Œè®¡æ•°ï¼ˆ`LongWritable`ï¼‰

`map()` æ–¹æ³•ï¼šè¯¥æ–¹æ³•è§£ææ¯è¡Œè¾“å…¥æ•°æ®ï¼Œæå–æ•°å€¼å¹¶åˆ†åˆ«è¾“å‡º sum å’Œ countã€‚

```java
public static class AvgMapper extends Mapper<LongWritable, Text, Text, LongWritable> {
    private final static Text SUM = new Text("sum");
    private final static Text COUNT = new Text("count");
    
    protected void map(LongWritable key, Text value, Context context) {
        // è¾“å…¥æ ¼å¼: "key value" (å¦‚ "1 39")
        // è¾“å‡ºä¸¤æ¡è®°å½•:
        // ("sum", æ•°å€¼)     - ç”¨äºç´¯åŠ æ€»å’Œ
        // ("count", 1)     - ç”¨äºè®¡æ•°
    }
}
```

Combiner ç±»ï¼š

åœ¨ `Job` é…ç½®ä¸­è®¾ç½®äº† `Combiner` ç±»ï¼Œè¿™æ„å‘³ç€åœ¨ Mapper é˜¶æ®µè¿›è¡Œå±€éƒ¨åˆå¹¶ï¼ˆä¾‹å¦‚æ±‚å’Œå’Œè®¡æ•°çš„åˆå¹¶ï¼‰ï¼Œè¿™æ ·å¯ä»¥å‡å°‘æ•°æ®ä¼ è¾“é‡ï¼Œæé«˜æ•ˆç‡ã€‚ç”±äºåŠ æ³•å’Œè®¡æ•°æ“ä½œæ»¡è¶³ç»“åˆå¾‹å’Œäº¤æ¢å¾‹ï¼Œ`Combiner` å¯ä»¥åƒ Reducer ä¸€æ ·å¤„ç†éƒ¨åˆ†æ•°æ®ï¼Œä¼˜åŒ–æ•´ä¸ª MapReduce çš„æ€§èƒ½ã€‚

```java
public static class AvgCombiner extends Reducer<Text, LongWritable, Text, LongWritable> {
    protected void reduce(Text key, Iterable<LongWritable> values, Context context) {
        // å¯¹ç›¸åŒé”®çš„å€¼è¿›è¡Œå±€éƒ¨æ±‚å’Œ
        // "sum"é”®ï¼šå¯¹éƒ¨åˆ†æ•°å€¼æ±‚å’Œ
        // "count"é”®ï¼šå¯¹éƒ¨åˆ†è®¡æ•°æ±‚å’Œ
        // è¾“å‡º: (key, local_sum) - ä¿æŒsum/countæ ¼å¼ä¸å˜
    }
}
```

Reducer ç±» `AvgReducer`ï¼š

`AvgReducer` ç±»å¯¹æ¥è‡ª Mapper çš„è¾“å‡ºè¿›è¡Œèšåˆï¼Œè®¡ç®—æ¯ä¸ª key å¯¹åº”çš„æ€»å’Œå’Œè®¡æ•°ï¼Œæœ€ç»ˆè®¡ç®—å‡ºå¹³å‡å€¼ã€‚å®ƒå°†å¤„ç† `"sum"` å’Œ `"count"` çš„ç»“æœï¼Œå¹¶è®¡ç®—å¹³å‡å€¼ã€‚

```java
public static class AvgReducer extends Reducer<Text, LongWritable, Text, DoubleWritable> {
    long sum = 0;
    long count = 0;
    
    protected void reduce(Text key, Iterable<LongWritable> values, Context context) {
        // å¤„ç†Combineråˆå¹¶åçš„ç»“æœ
        if (key.equals("sum")) {
            for (LongWritable v : values) sum += v.get();
        } else { // count
            for (LongWritable v : values) count += v.get();
        }
    }
    
    protected void cleanup(Context context) {
        // è®¡ç®—æœ€ç»ˆå¹³å‡å€¼
        double avg = (double) sum / count;
        context.write(new Text("Average"), new DoubleWritable(avg));
    }
}
```

Job é…ç½®ï¼š

åœ¨ `main()` æ–¹æ³•ä¸­ï¼Œé…ç½® Hadoop çš„ä½œä¸šï¼Œè®¾ç½®è¾“å…¥è¾“å‡ºè·¯å¾„ã€Mapper å’Œ Reducer ç±»ï¼Œå¹¶å®šä¹‰è¾“å‡ºæ•°æ®ç±»å‹ï¼Œè¿˜åŒ…å«äº† combiner çš„è®¾ç½®ï¼Œä»¥ä¾¿ Mapper å±‚è¿›è¡Œå±€éƒ¨åˆå¹¶ã€‚

```java
public static void main(String[] args) {
    Job job = Job.getInstance(conf, "average_with_combiner");
    
    job.setMapperClass(AvgMapper.class);
    job.setCombinerClass(AvgCombiner.class);  // å…³é”®ï¼šå¯ç”¨Combiner
    job.setReducerClass(AvgReducer.class);
    
    // è¾“å‡ºç±»å‹ï¼šText, LongWritable
    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
}
```



### ï¼ˆï¼•ï¼‰`AverageWrongCombiner.java`ä»£ç ç»“æ„

åŒ…åå’Œå¯¼å…¥è¯­å¥ï¼š

ä»£ç é¦–å…ˆå¯¼å…¥äº† Hadoop å’Œç›¸å…³çš„ I/O ç±»

ä¸»ç±» `AverageWrongCombiner`ï¼š

æ•´ä¸ªç¨‹åºçš„ä¸»ç±»ï¼Œç±»åä¸º `AverageWrongCombiner`ï¼Œç”¨äºè®¡ç®—å¹³å‡å€¼ï¼Œä½†æ­¤ä»£ç ä¸­ä½¿ç”¨äº†ä¸€ä¸ªé”™è¯¯çš„ combinerã€‚

```java
public static class AvgMapper extends Mapper<LongWritable, Text, Text, LongWritable> {
    private final static Text ONEKEY = new Text("avg");
    
    protected void map(LongWritable key, Text value, Context context) {
        // è¾“å…¥æ ¼å¼: "key value"
        // è¾“å‡º: ("avg", æ•°å€¼) - æ‰€æœ‰æ•°æ®ä½¿ç”¨åŒä¸€ä¸ªé”®
    }
}
```

Mapper ç±» `AvgMapper`ï¼š

è¯¥ç±»ç»§æ‰¿è‡ª `Mapper<LongWritable, Text, Text, LongWritable>`ï¼Œè´Ÿè´£å¤„ç†è¾“å…¥æ•°æ®å¹¶ç”Ÿæˆä¸­é—´è¾“å‡ºï¼Œä¸»è¦ä»»åŠ¡æ˜¯è§£æè¾“å…¥æ•°æ®ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªå›ºå®šçš„ key-value å¯¹ï¼š`"avg"` å’Œå¯¹åº”çš„æ•°å€¼ï¼ˆ`LongWritable`ï¼‰ã€‚

`map()` æ–¹æ³•ï¼šè¯¥æ–¹æ³•è§£ææ¯è¡Œè¾“å…¥æ•°æ®ï¼Œæå–æ•°å€¼å¹¶è¾“å‡º key `"avg"` å’Œå¯¹åº”çš„ valueã€‚

```java
public static class AvgMapper extends Mapper<LongWritable, Text, Text, LongWritable> {
    private final static Text ONEKEY = new Text("avg");
    
    protected void map(LongWritable key, Text value, Context context) {
        // è¾“å…¥æ ¼å¼: "key value"
        // è¾“å‡º: ("avg", æ•°å€¼) - æ‰€æœ‰æ•°æ®ä½¿ç”¨åŒä¸€ä¸ªé”®
    }
}
```

Reducer ç±» `AvgReducer`ï¼š

`AvgReducer` ç±»ä¼šå¯¹æ¥è‡ª Mapper çš„è¾“å‡ºè¿›è¡Œèšåˆï¼Œè®¡ç®—å¹³å‡å€¼ï¼Œå®ƒå°†å¤„ç† `"avg"` çš„æ‰€æœ‰æ•°å€¼å¹¶è®¡ç®—å‡ºæœ€ç»ˆçš„å¹³å‡å€¼ã€‚

é”™è¯¯çš„ Combiner è®¾ç½®ï¼š

ä»£ç ä¸­é”™è¯¯åœ°å°† `AvgReducer` è®¾ç½®ä¸º `Combiner`ï¼Œè¿™ä¼šå¯¼è‡´ `Combiner` çš„è¡Œä¸ºä¸æ­£ç¡®ï¼ŒCombiner æœ¬åº”åœ¨ Map é˜¶æ®µæ‰§è¡Œå±€éƒ¨åˆå¹¶ï¼ˆä¾‹å¦‚æ±‚å’Œå’Œè®¡æ•°ï¼‰ï¼Œä½†æ˜¯åœ¨è¿™ä¸ªé”™è¯¯çš„å®ç°ä¸­ï¼Œ`AvgReducer` è¢«ç”¨ä½œ `Combiner`ï¼Œå®ƒè®¡ç®—çš„æ˜¯æœ€ç»ˆçš„å¹³å‡å€¼ï¼Œè€Œä¸é€‚åˆåœ¨ Map é˜¶æ®µè¿›è¡Œå±€éƒ¨åˆå¹¶ã€‚

```java
public static class WrongCombiner extends Reducer<Text, LongWritable, Text, LongWritable> {
    protected void reduce(Text key, Iterable<LongWritable> values, Context context) {
        // âŒ é”™è¯¯åšæ³•ï¼šè®¡ç®—å±€éƒ¨å¹³å‡å€¼
        long sum = 0, count = 0;
        for (LongWritable v : values) {
            sum += v.get();
            count++;
        }
        long localAvg = sum / count;   // âŒ è®¡ç®—å±€éƒ¨å¹³å‡
        // è¾“å‡º: ("avg", localAvg) - ä¼ é€’çš„æ˜¯å¹³å‡å€¼è€ŒéåŸå§‹æ•°æ®
    }
}
```

```java
public static class WrongReducer extends Reducer<Text, LongWritable, Text, DoubleWritable> {
    protected void reduce(Text key, Iterable<LongWritable> values, Context context) {
        // âŒ å¯¹å±€éƒ¨å¹³å‡å€¼å†æ±‚å¹³å‡ï¼ˆé”™ä¸ŠåŠ é”™ï¼‰
        long sum = 0, count = 0;
        for (LongWritable v : values) {
            sum += v.get();  // è¿™é‡Œå¾—åˆ°çš„æ˜¯å„ä¸ªCombinerè¾“å‡ºçš„å±€éƒ¨å¹³å‡å€¼
            count++;
        }
        double wrongFinalAvg = (double) sum / count;
        // è¾“å‡º: ("WrongAverage", é”™è¯¯ç»“æœ)
    }
}
```

Job é…ç½®ï¼š

åœ¨ `main()` æ–¹æ³•ä¸­ï¼Œé…ç½® Hadoop çš„ä½œä¸šï¼Œè®¾ç½®è¾“å…¥è¾“å‡ºè·¯å¾„ã€Mapper å’Œ Reducer ç±»ï¼Œå¹¶å®šä¹‰è¾“å‡ºæ•°æ®ç±»å‹ã€‚è¿™éƒ¨åˆ†é…ç½®ä¸æ ‡å‡†çš„ MapReduce ä½œä¸šé…ç½®ç›¸åŒï¼Œä½†ä½¿ç”¨äº†ä¸é€‚å½“çš„ `Combiner` è®¾ç½®ã€‚

```java
public static void main(String[] args) {
    Job job = Job.getInstance(conf, "average_wrong_combiner");
    
    job.setMapperClass(AvgMapper.class);
    job.setCombinerClass(WrongCombiner.class);   // âŒ ä½¿ç”¨é”™è¯¯çš„Combiner
    job.setReducerClass(WrongReducer.class);
    
    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
}
```

## 3.å®éªŒæ­¥éª¤

### 3.1é›†ç¾¤ä¸è¿è¡Œç¯å¢ƒåˆå§‹åŒ–

è§1.3

### 3.2ä¸Šä¼ æ•°æ®å’Œä»£ç 

**1.å‡†å¤‡å¥½æ•°æ®å¹¶ä¸Šä¼ è‡³HDFS**

ä¸Šä¼ pythonè„šæœ¬æ–‡ä»¶ã€ç”Ÿæˆæ•°æ®é›†ã€ä¸Šä¼ æ•°æ®é›†è‡³HDFS



**2.ä¸Šä¼ ä»£ç **

æœ¬åœ°å†™å¥½Javaä»£ç åå°†javaæ–‡ä»¶ä¸Šä¼ åˆ°èŠ‚ç‚¹



**3.å¹¶ä½¿ç”¨Hadoopçš„classç¼–è¯‘**

**4.åœ¨Linuxä¸Šæ‰“åŒ…æˆjar**

### 3.3è¿›è¡Œå®éªŒ

**1.æ¯ä¸ªèŠ‚ç‚¹åˆ†åˆ«åœ¨ä¸åŒæ•°æ®é›†æ‰§è¡Œä»»åŠ¡ï¼Œä¾æ¬¡è¿è¡Œæœ‰/æ— combinerçš„å®éªŒ**

è¿è¡Œä¹‹å‰éœ€è¦ç¡®è®¤è‡ªå·±çš„è¾“å‡ºç›®å½•ä¸ºç©º



è¿è¡Œç»“æŸåï¼Œå¯åœ¨æ§åˆ¶å°ç¡®è®¤ä½œä¸šæ˜¯å¦æˆåŠŸï¼Œå¦‚å›¾å‡ºç°

- `map 100% reduce 100%`
- `Job job_xxx completed successfully`
  å³ä¸ºæˆåŠŸ

![é¡¹ç›®æˆªå›¾](https://github.com/LornaLiang/DasebigdataAssignmentGroup32/blob/15e862c22e1701975e751523d81eb98b85aa6bd3/image/yqr_img/real2.png)

**2.å®éªŒæˆåŠŸååœ¨Web UIä¸­æŸ¥çœ‹ä½œä¸šè¯¦æƒ…å¹¶è®°å½•æ•°æ®**

Web Uiç•Œé¢ä¸­YARN ResourceManager UIå¯æ€»è§ˆæ‰€æœ‰YARNä»»åŠ¡

![é¡¹ç›®æˆªå›¾](https://github.com/LornaLiang/DasebigdataAssignmentGroup32/blob/cdf132d76716b60df7ef34130b9a047e301f4262/image/yqr_img/application.png)

MapReduce Job History UIèƒ½å¤Ÿçœ‹åˆ°å·²ç»å®Œæˆçš„ MapReduce Jobï¼Œå¹¶ä¸”èƒ½å¤Ÿè·å–æ›´ç»†è‡´çš„æƒ…å†µ

![é¡¹ç›®æˆªå›¾](https://github.com/LornaLiang/DasebigdataAssignmentGroup32/blob/cdf132d76716b60df7ef34130b9a047e301f4262/image/yqr_img/jobhistory.png)

å¦‚å›¾æ‰€ç¤ºï¼Œåœ¨MapReduce Jobçš„Overviewç•Œé¢æŸ¥çœ‹MapReduceçš„æ‰§è¡Œæ—¶é—´

![é¡¹ç›®æˆªå›¾](https://github.com/LornaLiang/DasebigdataAssignmentGroup32/blob/15e862c22e1701975e751523d81eb98b85aa6bd3/image/yqr_img/uniform_noc/1.png)

å¦‚å›¾æ‰€ç¤ºï¼Œä»¥Mapçš„countersä¸ºä¾‹ï¼Œå¯ä»¥è®°å½•æœ¬æ¬¡å®éªŒçš„å…³é”®æŒ‡æ ‡ï¼Œå¦‚ï¼š

- Map Output Records
- Map Output Bytes
- Map Output Materialized Bytes
  ç­‰

Reduceçš„æ•°æ®åŒç†

![é¡¹ç›®æˆªå›¾](https://github.com/LornaLiang/DasebigdataAssignmentGroup32/blob/15e862c22e1701975e751523d81eb98b85aa6bd3/image/yqr_img/uniform_noc/mapcounters1.png)

### 3.3å®éªŒæ•°æ®æ•´ç†ä¸å¯¼å‡º

å„ç»„å‘˜å°†æ•°æ®æ±‡é›†åˆ°è¡¨æ ¼ä¸­ï¼Œæ–¹ä¾¿è¿›è¡Œåç»­çš„å›¾è¡¨ç»˜åˆ¶ä¸æ•°æ®åˆ†æ

>>>>>>> Stashed changes
=======

æœ¬å®éªŒä¸€å…±æ„é€ äº†9ä¸ªæ•°æ®é›†ã€‚å…¶ä¸­ï¼Œ8ä¸ªæ•°æ®é›†ç”¨äºç ”ç©¶åœ¨ä¸åŒè§„æ¨¡å’Œkeyåˆ†å¸ƒä¸‹Combinerçš„æ•ˆæœï¼š

- **å‡è¡¡æ•°æ®é›†**ï¼ˆkey å‡åŒ€åˆ†å¸ƒï¼‰ï¼š
  - 25MBã€50MBã€100MB ä¸‰ä¸ªè§„æ¨¡ã€‚
  - å„ä¸ª key å‡ºç°æ¬¡æ•°å¤§è‡´ç›¸åŒï¼Œæ²¡æœ‰æ˜æ˜¾çƒ­ç‚¹ keyã€‚
- **å€¾æ–œæ•°æ®é›†ï¼ˆ60%ï¼‰**ï¼š
  - 25MBã€50MBã€100MB ä¸‰ä¸ªè§„æ¨¡ã€‚
  - çº¦ 60% çš„è®°å½•é›†ä¸­åœ¨å°‘æ•°çƒ­ç‚¹ key ä¸Šï¼Œå…¶ä½™è®°å½•åˆ†å¸ƒåœ¨å…¶ä»– key ä¸Šã€‚
- **å€¾æ–œæ•°æ®é›†ï¼ˆ90%ï¼‰**ï¼š
  - 100MBã€200MB ä¸¤ä¸ªè§„æ¨¡ã€‚
  - çº¦ 90% çš„è®°å½•é›†ä¸­åœ¨æ›´å°‘æ•°çš„çƒ­ç‚¹ key ä¸Šï¼Œæ•°æ®å€¾æ–œæ›´ä¸¥é‡ã€‚

è¿™8ä¸ªæ•°æ®é›†ç”¨äºæ±‚å’Œä»»åŠ¡ï¼Œæ¯æ¡æ•°æ®çš„è®°å½•æ ¼å¼ä¸ºï¼škey valueï¼Œå…¶ä¸­keyä¸ºintå‹ï¼Œvalueå€¼å‡ä¸º1ã€‚

avg_50MBæ•°æ®é›†ç”¨äºæ±‚å¹³å‡å€¼çš„ä»»åŠ¡ï¼Œkeyå€¼å‡ä¸º1ï¼Œvalueå€¼ä¸ºintå‹ã€‚

## 2.2 ä»»åŠ¡æè¿°

### ä»»åŠ¡ä¸€ï¼škey-valueæ±‚å’Œï¼ˆæœ‰æ— Combinerï¼‰

ä»»åŠ¡ç›®æ ‡æ˜¯å¯¹è¾“å…¥æ•°æ®ä¸­çš„æ‰€æœ‰è®°å½•ï¼ŒæŒ‰ç…§keyè¿›è¡Œvalueçš„æ±‚å’Œï¼Œè¾“å‡ºæ¯ä¸ªkeyçš„æ€»å’Œç»“æœã€‚

åœ¨Mapé˜¶æ®µï¼Œå¯¹äºè¾“å…¥çš„æ–‡æœ¬è¡Œâ€œkey valueâ€ï¼Œä¼šè§£æå‡ºå­—ç¬¦ä¸²keyå’Œæ•´æ•°valueç„¶åè¾“å‡ºä¸­é—´é”®å€¼å¯¹ï¼ˆkey,value)ã€‚åœ¨Combineré˜¶æ®µï¼Œä¸Reducerä¸€æ ·ï¼Œä¼šåœ¨Mapä»»åŠ¡çš„è¾“å‡ºé˜¶æ®µå¯¹ç›¸åŒkeyçš„valueè¿›è¡Œå±€éƒ¨æ±‚å’Œï¼Œä»¥æ­¤æ¥ä»‹ç»å‘å¾€ä¸‹æ¸¸çš„ä¸­é—´é”®å€¼å¯¹çš„æ•°é‡ï¼Œä»è€Œå‡å°‘ç½‘ç»œä¼ è¾“å’ŒReduceç«¯çš„è´Ÿè½½ã€‚åœ¨Reduceæç«¯ï¼ŒReducerä¼šæ¥æ”¶æ¥è‡ªå¤šä¸ªMap/Combinerçš„(key,valueSum)å¯¹ï¼Œå®Œæˆå…¨å±€æ±‚å’Œã€‚

å®éªŒè®¾è®¡ä¸Šï¼Œæˆ‘ä»¬å¯¹æ¯ä¸ªæ•°æ®é›†éƒ½è¿›è¡Œä¸¤æ¬¡å®éªŒã€‚å½“å…³é—­Combineræ—¶ï¼ŒMapçš„è¾“å‡ºä¼šç›´æ¥è¿›å…¥Shuffleé˜¶æ®µï¼›å½“å¼€å¯Combineræ—¶ï¼Œä¼šåœ¨MapèŠ‚ç‚¹è¿›è¡Œå±€éƒ¨èšåˆã€‚é€šè¿‡åœ¨ä¸åŒå€¾æ–œåº¦çš„æ•°æ®é›†ä»¥åŠä¸åŒå¤§å°çš„æ•°æ®é›†ä¸Šè¿›è¡Œå®éªŒï¼Œæ¥æ¢ç©¶æœ‰æ— Combinerå¯¹MapReduceä½œä¸šæ€§èƒ½çš„å½±å“ã€‚

### ä»»åŠ¡äºŒï¼šæŒ‰keyæ±‚å¹³å‡å€¼

ä»»åŠ¡ç›®æ ‡æ˜¯å¯¹50MBçš„å‡è¡¡æ•°æ®é›†keyè®¡ç®—valueçš„å¹³å‡å€¼ã€‚

ç›´æ¥åœ¨Combinerä¸­å¯¹valueæ±‚å¹³å‡å€¼ï¼Œç„¶åå†åœ¨Reducerä¸­å¯¹è¿™äº›â€œå±€éƒ¨å¹³å‡å€¼â€å†æ±‚å¹³å‡ä¼šå¾—å‡ºé”™è¯¯çš„ç»“æœï¼Œå› ä¸ºâ€œå¹³å‡å€¼â€æœ¬èº«ä¸æ»¡è¶³ç®€å•çš„ç»“åˆå¾‹ã€‚æ‰€ä»¥åœ¨æ±‚å¹³å‡å€¼æ—¶ï¼Œéœ€è¦æ”¹å˜MapReduceçš„å¹³å‡å€¼è®¡ç®—æ¨¡å¼ï¼šå°†å¹³å‡å€¼æ‹†åˆ†ä¸ºsumå’Œcountä¸¤ä¸ªéƒ¨åˆ†ã€‚è¿™ä¸¤ä¸ªéƒ¨åˆ†å¯ä»¥è¿›è¡Œå¯ç»“åˆçš„åŠ æ³•æ“ä½œï¼Œå¾—å‡ºæ­£ç¡®çš„ç»“æœã€‚

åœ¨Mapé˜¶æ®µå¯¹äºè¾“å…¥çš„æ¯ä¸€æ¡è®°å½•ï¼Œè¾“å‡º(sum,value)å’Œï¼ˆcount,1)ï¼Œè¾“å…¥Combineré˜¶æ®µï¼Œä¼šå¯¹sumå’Œcountè¿›è¡Œåˆ†åˆ«æ±‚å’Œï¼Œè¿™æ—¶Combineråªåšäº†åŠ æ³•ï¼Œæ»¡è¶³äº†ç»“åˆå¾‹å’Œäº¤æ¢å¾‹ï¼Œä¸ä¼šå½±å“æœ€ç»ˆçš„ç»“æœï¼ŒåŒæ—¶ä¹Ÿå¤§å¹…åº¦å‡å°‘äº†ä¼ è¾“åˆ°Reducerçš„ä¸­é—´é”®å€¼å¯¹æ•°é‡ã€‚Reduceræœ€åå¯¹å¤šä¸ªMap/Combinerè¾“å‡ºçš„å€¼è¿›è¡Œç´¯åŠ ï¼Œå¾—åˆ°å…¨å±€çš„(sum,count)å¹¶æ±‚å‡ºå¹³å‡å€¼ã€‚

è¯¥ä»»åŠ¡åªåœ¨avg_50MBä¸€ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œé€šè¿‡å¯¹æ¯”åœ¨ä¸ä½¿ç”¨Combinerã€ä½¿ç”¨é”™è¯¯çš„æ¨¡å¼ä»¥åŠä½¿ç”¨æ­£ç¡®çš„æ”¯æŒCombinerçš„æ¨¡å¼è¿™ä¸‰ç§æƒ…å†µä¸‹çš„ç»“æœï¼Œæ¢ç©¶Combineré€‚åˆä½¿ç”¨çš„ä»»åŠ¡åœºæ™¯ï¼Œè®¾è®¡å‡ºé€‚åˆCombinerçš„èšåˆé€»è¾‘ã€‚

__é€šè¿‡ä¸Šè¿°ä¸¤ç±»å·¥ä½œè´Ÿè½½ä¸å¤šç»„æ•°æ®é›†çš„ç»“åˆï¼Œæœ¬å®éªŒå¯ä»¥ç³»ç»Ÿå›ç­”ä»¥ä¸‹é—®é¢˜ï¼š__

1.Combineræ˜¯å¦èƒ½å¤Ÿæœ‰æ•ˆå‡å°‘Shuffleé˜¶æ®µçš„æ•°æ®é‡ï¼Ÿ

2.åœ¨ä¸åŒå€¾æ–œåº¦çš„æ•°æ®é›†ä¸Šï¼ŒCombinerçš„æ€§èƒ½æå‡æœ‰ä½•å·®å¼‚ï¼Ÿ

3.æ˜¯å¦æ‰€æœ‰åœºæ™¯éƒ½é€‚åˆä½¿ç”¨Combinerï¼Ÿ

> [!IMPORTANT]
>
> ### ä¸ºä»€ä¹ˆkey-value æ±‚å’Œä»»åŠ¡é€‚åˆç”¨ combiner
>
> å› ä¸ºCombineræœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªåœ¨Mapç«¯çš„â€œè¿·ä½ Reducerâ€ï¼Œå®ƒå¿…é¡»èƒ½å¤Ÿä»¥ä»»æ„é¡ºåºã€ä»»æ„åˆ†ç»„æ–¹å¼å¤„ç†Mapè¾“å‡ºçš„ä¸­é—´ç»“æœï¼Œè€Œä¸å½±å“æœ€ç»ˆç»“æœçš„æ­£ç¡®å®šæ€§ï¼Œè€Œç»“åˆå¾‹å’Œäº¤æ¢å¾‹æ­£æ˜¯ä¿è¯è¿™ç§â€œä»»æ„æ€§â€ä¸ä¼šå¯¼è‡´é”™è¯¯çš„å…³é”®å±æ€§ã€‚
>
> Combinerçš„ä½œç”¨
>
> ã€€ã€€åœ¨MapReduceä¸­ï¼ŒCombinerçš„ä½œç”¨æ˜¯åœ¨Mapä»»åŠ¡å®Œæˆåï¼Œåœ¨æœ¬åœ°å…ˆå¯¹è¾“å‡ºçš„<key, value>å¯¹è¿›è¡Œä¸€æ¬¡åˆå¹¶ï¼Œç„¶åå†å°†ç»“æœé€šè¿‡ç½‘ç»œå‘é€ç»™Reducerã€‚
>
> ã€€ã€€ç›®çš„ï¼šå‡å°‘Mapå’ŒReduceä»»åŠ¡ä¹‹é—´çš„ç½‘ç»œä¼ è¾“æ•°æ®é‡ï¼Œæå‡æ•´ä½“ä½œä¸šæ€§èƒ½ã€‚
>
> ã€€ã€€è¿è¡Œä½ç½®ï¼šå®ƒåœ¨æ¯ä¸ªMapä»»åŠ¡èŠ‚ç‚¹ä¸Šè¿è¡Œï¼Œå¤„ç†è¯¥Mapä»»åŠ¡è‡ªå·±äº§ç”Ÿçš„ä¸­é—´ç»“æœã€‚
>
> å› ä¸ºåŠ æ³•æ»¡è¶³ç»“åˆå¾‹å’Œäº¤æ¢å¾‹ï¼Œè¿™ä¸¤ä¸ªæ€§è´¨ä¿è¯äº†æ— è®ºæ•°æ®æ˜¯å¦‚ä½•åˆ†å¸ƒçš„ï¼Œåªè¦æœ€ç»ˆçš„æ“ä½œæ˜¯åŠ æ³•ï¼Œç»“æœå°†å§‹ç»ˆæ˜¯ä¸€æ ·çš„ã€‚è¿™æ­£æ˜¯ä½¿ç”¨combineræ—¶çš„æ ¸å¿ƒä¼˜åŠ¿ã€‚
>
> åœ¨ MapReduce ä¸­ï¼Œæ•°æ®ä» Map é˜¶æ®µä¼ è¾“åˆ° Reduce é˜¶æ®µæ—¶ï¼Œä¼ è¾“çš„ä¸­é—´æ•°æ®é‡å¯èƒ½ä¼šéå¸¸å¤§ã€‚é€šè¿‡ä½¿ç”¨ combinerï¼Œæˆ‘ä»¬å¯ä»¥åœ¨Map ä»»åŠ¡çš„èŠ‚ç‚¹ä¸Šå¯¹ç›¸åŒçš„ key è¿›è¡Œå±€éƒ¨æ±‚å’Œï¼Œç„¶åå°†æ±‚å’Œç»“æœä¼ é€’ç»™ Reducerã€‚è¿™æ ·å¯ä»¥æ˜¾è‘—å‡å°‘éœ€è¦ä¼ è¾“åˆ°Reducer çš„æ•°æ®é‡ã€‚
>
> ç”±äºåŠ æ³•çš„ç»“åˆå¾‹å’Œäº¤æ¢å¾‹ï¼Œå±€éƒ¨åˆå¹¶çš„é¡ºåºä¸ä¼šå½±å“æœ€ç»ˆç»“æœã€‚å³ä½¿ä¸åŒçš„ Map ä»»åŠ¡åœ¨ä¸åŒçš„èŠ‚ç‚¹ä¸Šå¹¶è¡Œè¿è¡Œï¼ŒReducer ä»ç„¶èƒ½å¤Ÿå¾—åˆ°æ­£ç¡®çš„æ€»å’Œï¼Œå› ä¸ºå„ä¸ªèŠ‚ç‚¹ä¸Šçš„å±€éƒ¨ç»“æœä¼šè¢«åˆå¹¶æˆæœ€ç»ˆçš„æ­£ç¡®ç»“æœã€‚è¿™ä¿è¯äº†åˆ†å¸ƒå¼è®¡ç®—ä¸­çš„ä¸€è‡´æ€§å’Œæ­£ç¡®æ€§ã€‚
>
> ä½¿ç”¨ combiner å¯ä»¥å‡å°‘ Reducer ç«¯çš„è®¡ç®—è´Ÿæ‹…ï¼Œå› ä¸ºå®ƒæ”¶åˆ°çš„æ•°æ®å·²ç»æ˜¯éƒ¨åˆ†åˆå¹¶è¿‡çš„ã€‚ä¾‹å¦‚ï¼ŒReducer ä¸éœ€è¦é‡å¤è®¡ç®—æ¯ä¸ª key çš„æ‰€æœ‰å€¼çš„å’Œï¼Œè€Œæ˜¯ç›´æ¥å¯¹å±€éƒ¨åˆå¹¶çš„ç»“æœè¿›è¡Œå¤„ç†ï¼Œè¿›ä¸€æ­¥æé«˜äº†è®¡ç®—æ•ˆç‡ã€‚



## 2.3 ç®€è¦æè¿°Java ä»£ç ç»“æ„ï¼ˆåŒ…åã€ç±»åã€ä¸»è¦å‡½æ•°ï¼‰

### ï¼ˆ1ï¼‰`SumWithCombiner.java` ä»£ç ç»“æ„

åŒ…åå’Œå¯¼å…¥è¯­å¥ï¼š

å¼•å…¥äº†å¿…è¦çš„ Hadoop ç±»å’Œ IO åº“ã€‚

```java
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.*;
import org.apache.hadoop.mapreduce.*;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
```

ä¸»ç±» `SumWithCombiner`ï¼š

è¿™æ˜¯æ•´ä¸ªç¨‹åºçš„æ ¸å¿ƒç±»ï¼ŒåŒ…å«äº† MapReduce ä»»åŠ¡çš„å®ç°ã€‚

Mapper ç±» `SumMapper`ï¼š

`SumMapper` ç»§æ‰¿è‡ª `Mapper<LongWritable, Text, Text, IntWritable>`ï¼Œè´Ÿè´£å¤„ç†è¾“å…¥æ•°æ®å¹¶ç”Ÿæˆ key-value å¯¹ã€‚

`map()` æ–¹æ³•ï¼šè¾“å…¥æ¯ä¸€è¡Œæ•°æ®ï¼ˆ`LongWritable` å’Œ `Text`ï¼‰ï¼Œå°†å…¶æ‹†åˆ†åç”Ÿæˆç›¸åº”çš„ key å’Œ valueï¼ˆ`Text` å’Œ `IntWritable`ï¼‰ã€‚

```java
public static class SumMapper extends Mapper<LongWritable, Text, Text, IntWritable> {
    private Text outKey = new Text();
    private IntWritable outValue = new IntWritable();
    
    protected void map(LongWritable key, Text value, Context context) {
        // æŒ‰ç©ºæ ¼åˆ†å‰²è¾“å…¥è¡Œ
        // æå–ç¬¬ä¸€ä¸ªå­—æ®µä½œä¸ºkeyï¼Œç¬¬äºŒä¸ªå­—æ®µä½œä¸ºvalue
        // è¾“å‡º: (key, value)
    }
}
```

Reducer ç±» `SumReducer`ï¼š

`SumReducer` ç»§æ‰¿è‡ª `Reducer<Text, IntWritable, Text, IntWritable>`ï¼Œè´Ÿè´£å¯¹ `Mapper` è¾“å‡ºçš„ key-value å¯¹è¿›è¡Œèšåˆï¼Œè®¡ç®—æ¯ä¸ª key çš„æ€»å’Œã€‚

```java
public static class SumReducer extends Reducer<Text, IntWritable, Text, IntWritable> {
    protected void reduce(Text key, Iterable<IntWritable> values, Context context) {
        // å¯¹ç›¸åŒkeyçš„æ‰€æœ‰valueè¿›è¡Œæ±‚å’Œ
        // è¾“å‡º: (key, sum)
    }
}
```

Job é…ç½®ï¼š

åœ¨ `main()` æ–¹æ³•ä¸­ï¼Œé…ç½® Hadoop çš„ Jobï¼Œè®¾ç½®è¾“å…¥è¾“å‡ºè·¯å¾„ã€Mapperã€Reducer ç±»ï¼Œå¹¶æŒ‡å®šè¾“å‡ºçš„æ•°æ®ç±»å‹ï¼Œè®¾ç½® `Combiner`ï¼ˆæ­¤ä»£ç ä¸­é€šè¿‡ `job.setCombinerClass(SumReducer.class)` è®¾ç½®äº† `Combiner`ï¼‰ã€‚

```java
public static void main(String[] args) {
    // åˆ›å»ºJobå®ä¾‹
    Job job = Job.getInstance(conf, "Sum With Combiner");
    
    // è®¾ç½®Mapperå’ŒReducerç±»
    job.setMapperClass(SumMapper.class);
    job.setReducerClass(SumReducer.class);
    
    // å…³é”®ï¼šå¯ç”¨Combinerï¼Œç›´æ¥ä½¿ç”¨Reducerä½œä¸ºCombiner
    job.setCombinerClass(SumReducer.class);
    
    // è®¾ç½®è¾“å…¥è¾“å‡ºè·¯å¾„
    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
}
```



### ï¼ˆï¼’ï¼‰`SumNoCombiner.java` ä»£ç ç»“æ„

åŒ…åå’Œå¯¼å…¥è¯­å¥ï¼š

å¼•å…¥äº†å¿…è¦çš„ Hadoop ç±»å’Œ IO åº“ã€‚

```java
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.*;
import org.apache.hadoop.mapreduce.*;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
```

ä¸»ç±» `SumNoCombiner`ï¼š

è¿™æ˜¯æ•´ä¸ªç¨‹åºçš„æ ¸å¿ƒç±»ï¼ŒåŒ…å«äº† MapReduce ä»»åŠ¡çš„å®ç°ï¼Œæ²¡æœ‰ä½¿ç”¨ Combinerã€‚

Mapper ç±» `SumMapper`ï¼š

`SumMapper` ç»§æ‰¿è‡ª `Mapper<LongWritable, Text, Text, IntWritable>`ï¼Œä¸å‰ä¸€ä¸ªç‰ˆæœ¬ç›¸ä¼¼ï¼Œè´Ÿè´£è¾“å…¥æ•°æ®çš„å¤„ç†å¹¶è¾“å‡º key-value å¯¹ã€‚

```java
public static class SumMapper extends Mapper<LongWritable, Text, Text, IntWritable> {
    private Text outKey = new Text();
    private IntWritable outValue = new IntWritable();
    
    protected void map(LongWritable key, Text value, Context context) {
        // è¾“å…¥æ ¼å¼: "key value"
        // æŒ‰ç©ºæ ¼åˆ†å‰²è¾“å…¥è¡Œ
        // è¾“å‡º: (Text_key, IntWritable_value)
    }
}
```

Reducer ç±» `SumReducer`ï¼š

è´Ÿè´£å¯¹ `Mapper` è¾“å‡ºçš„ key-value å¯¹è¿›è¡Œåˆå¹¶æ“ä½œï¼Œè®¡ç®—æ¯ä¸ª key çš„æ€»å’Œã€‚

```java
public static class SumReducer extends Reducer<Text, IntWritable, Text, IntWritable> {
    protected void reduce(Text key, Iterable<IntWritable> values, Context context) {
        // å¯¹ç›¸åŒkeyçš„æ‰€æœ‰valuesè¿›è¡Œæ±‚å’Œ
        int sum = 0;
        for (IntWritable v : values) {
            sum += v.get();
        }
        // è¾“å‡º: (key, total_sum)
    }
}
```

Job é…ç½®ï¼š

åœ¨ `main()` æ–¹æ³•ä¸­ï¼Œé…ç½® Hadoop ä½œä¸šï¼Œè®¾ç½®è¾“å…¥è¾“å‡ºè·¯å¾„ã€Mapperã€Reducer ç±»ï¼Œå¹¶æŒ‡å®šè¾“å‡ºçš„æ•°æ®ç±»å‹ï¼Œæ²¡æœ‰ä½¿ç”¨ `Combiner`ï¼Œæ‰€æœ‰çš„åˆå¹¶å·¥ä½œç”± `Reducer` å®Œæˆã€‚

```java
public static void main(String[] args) {
    // åˆ›å»ºJobå®ä¾‹
    Job job = Job.getInstance(conf, "Sum No Combiner");
    
    // è®¾ç½®Mapperå’ŒReducerç±»
    job.setMapperClass(SumMapper.class);
    job.setReducerClass(SumReducer.class);
    
    // å…³é”®åŒºåˆ«ï¼šæ²¡æœ‰è®¾ç½®Combiner
    // job.setCombinerClass(...);  // æ­¤è¡Œç¼ºå¤±
    
    // è®¾ç½®è¾“å…¥è¾“å‡ºè·¯å¾„
    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
}
```



### ï¼ˆï¼“ï¼‰`AverageNoCombiner.java` ä»£ç ç»“æ„

åŒ…åå’Œå¯¼å…¥è¯­å¥ï¼š

ä»£ç é¦–å…ˆå¯¼å…¥äº† Hadoop å’Œç›¸å…³çš„ I/O ç±»ï¼Œè§ï¼ˆ1ï¼‰ã€‚

ä¸»ç±» `AverageNoCombiner`ï¼š

æ•´ä¸ªç¨‹åºçš„ä¸»ç±»ï¼Œç±»åä¸º `AverageNoCombiner`ï¼Œç”¨äºè®¡ç®—å¹³å‡å€¼ï¼ˆæ²¡æœ‰ä½¿ç”¨combinerï¼‰ã€‚

Mapper ç±» `AvgMapper`ï¼š

è¯¥ç±»ç»§æ‰¿è‡ª `Mapper<LongWritable, Text, Text, LongWritable>`ï¼Œç”¨äºå¤„ç†è¾“å…¥æ•°æ®å¹¶ç”Ÿæˆä¸­é—´è¾“å‡ºï¼Œä¸»è¦ä»»åŠ¡æ˜¯è§£æè¾“å…¥æ•°æ®ï¼Œå¹¶ç”Ÿæˆä¸¤ä¸ª key-value å¯¹`"sum"` å’Œæ€»å’Œï¼ˆ`LongWritable`ï¼‰ï¼Œ `"count"` å’Œè®¡æ•°ï¼ˆ`LongWritable`ï¼‰

`map()` æ–¹æ³•ï¼šè¯¥æ–¹æ³•è§£ææ¯è¡Œè¾“å…¥æ•°æ®ï¼Œæå–æ•°å€¼å¹¶åˆ†åˆ«è¾“å‡º sum å’Œ countã€‚

```java
public static class AvgMapper extends Mapper<LongWritable, Text, Text, LongWritable> {
    private final static Text SUM = new Text("sum");
    private final static Text COUNT = new Text("count");
    
    protected void map(LongWritable key, Text value, Context context) {
        // è¾“å…¥æ ¼å¼: "key value" (å¦‚ "1 39")
        // è¾“å‡ºä¸¤æ¡è®°å½•:
        // ("sum", æ•°å€¼)     - ç”¨äºç´¯åŠ æ€»å’Œ
        // ("count", 1)     - ç”¨äºè®¡æ•°
    }
}
```

Reducer ç±» `AvgReducer`ï¼š

`AvgReducer` ç±»å¯¹æ¥è‡ª Mapper çš„è¾“å‡ºè¿›è¡Œèšåˆï¼Œè®¡ç®—æ¯ä¸ª key å¯¹åº”çš„æ€»å’Œå’Œè®¡æ•°ï¼Œæœ€ç»ˆè®¡ç®—å‡ºå¹³å‡å€¼ï¼Œå®ƒå°†å¤„ç† `"sum"` å’Œ `"count"` çš„ç»“æœï¼Œå¹¶è®¡ç®—å¹³å‡å€¼ã€‚

```java
public static class AvgReducer extends Reducer<Text, LongWritable, Text, DoubleWritable> {
    long sum = 0;
    long count = 0;
    
    protected void reduce(Text key, Iterable<LongWritable> values, Context context) {
        // åˆ†åˆ«å¤„ç†"sum"å’Œ"count"é”®
        if (key.equals("sum")) {
            for (LongWritable val : values) sum += val.get();
        } else { // count
            for (LongWritable val : values) count += val.get();
        }
    }
    
    protected void cleanup(Context context) {
        // åœ¨æ‰€æœ‰reduceå®Œæˆåè®¡ç®—æœ€ç»ˆå¹³å‡å€¼
        double avg = (double) sum / count;
        context.write(new Text("Average"), new DoubleWritable(avg));
    }
}
```

Job é…ç½®ï¼š

åœ¨ `main()` æ–¹æ³•ä¸­ï¼Œé…ç½® Hadoop çš„ä½œä¸šï¼Œè®¾ç½®è¾“å…¥è¾“å‡ºè·¯å¾„ã€Mapper å’Œ Reducer ç±»ï¼Œå¹¶å®šä¹‰è¾“å‡ºæ•°æ®ç±»å‹ã€‚

 

```java
public static void main(String[] args) {
    Job job = Job.getInstance(conf, "average_no_combiner");
    
    job.setMapperClass(AvgMapper.class);
    job.setReducerClass(AvgReducer.class);
    
    // æ³¨æ„ï¼šæ²¡æœ‰è®¾ç½®Combiner
    // è¾“å‡ºç±»å‹ï¼šText, LongWritable (Mapperè¾“å‡ºç±»å‹)
    
    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
}
```



### ï¼ˆ4ï¼‰`AverageWithCombiner.java`ä»£ç ç»“æ„

åŒ…åå’Œå¯¼å…¥è¯­å¥ï¼š

ä»£ç é¦–å…ˆå¯¼å…¥äº† Hadoop å’Œç›¸å…³çš„ I/O ç±»

ä¸»ç±» `AverageWithCombiner`ï¼š

æ•´ä¸ªç¨‹åºçš„ä¸»ç±»ï¼Œç±»åä¸º `AverageWithCombiner`ï¼Œç”¨äºè®¡ç®—å¹³å‡å€¼ï¼Œå¹¶ä½¿ç”¨äº† combiner æ¥ä¼˜åŒ–æ€§èƒ½ã€‚

Mapper ç±» `AvgMapper`ï¼š

è¯¥ç±»ç»§æ‰¿è‡ª `Mapper<LongWritable, Text, Text, LongWritable>`ï¼Œè´Ÿè´£å¤„ç†è¾“å…¥æ•°æ®å¹¶ç”Ÿæˆä¸­é—´è¾“å‡ºï¼Œä¸»è¦ä»»åŠ¡æ˜¯è§£æè¾“å…¥æ•°æ®ï¼Œå¹¶ç”Ÿæˆä¸¤ä¸ª key-value å¯¹ï¼š`"sum"` å’Œæ€»å’Œï¼ˆ`LongWritable`ï¼‰å’Œ`"count"` å’Œè®¡æ•°ï¼ˆ`LongWritable`ï¼‰

`map()` æ–¹æ³•ï¼šè¯¥æ–¹æ³•è§£ææ¯è¡Œè¾“å…¥æ•°æ®ï¼Œæå–æ•°å€¼å¹¶åˆ†åˆ«è¾“å‡º sum å’Œ countã€‚

```java
public static class AvgMapper extends Mapper<LongWritable, Text, Text, LongWritable> {
    private final static Text SUM = new Text("sum");
    private final static Text COUNT = new Text("count");
    
    protected void map(LongWritable key, Text value, Context context) {
        // è¾“å…¥æ ¼å¼: "key value" (å¦‚ "1 39")
        // è¾“å‡ºä¸¤æ¡è®°å½•:
        // ("sum", æ•°å€¼)     - ç”¨äºç´¯åŠ æ€»å’Œ
        // ("count", 1)     - ç”¨äºè®¡æ•°
    }
}
```

Combiner ç±»ï¼š

åœ¨ `Job` é…ç½®ä¸­è®¾ç½®äº† `Combiner` ç±»ï¼Œè¿™æ„å‘³ç€åœ¨ Mapper é˜¶æ®µè¿›è¡Œå±€éƒ¨åˆå¹¶ï¼ˆä¾‹å¦‚æ±‚å’Œå’Œè®¡æ•°çš„åˆå¹¶ï¼‰ï¼Œè¿™æ ·å¯ä»¥å‡å°‘æ•°æ®ä¼ è¾“é‡ï¼Œæé«˜æ•ˆç‡ã€‚ç”±äºåŠ æ³•å’Œè®¡æ•°æ“ä½œæ»¡è¶³ç»“åˆå¾‹å’Œäº¤æ¢å¾‹ï¼Œ`Combiner` å¯ä»¥åƒ Reducer ä¸€æ ·å¤„ç†éƒ¨åˆ†æ•°æ®ï¼Œä¼˜åŒ–æ•´ä¸ª MapReduce çš„æ€§èƒ½ã€‚

```java
public static class AvgCombiner extends Reducer<Text, LongWritable, Text, LongWritable> {
    protected void reduce(Text key, Iterable<LongWritable> values, Context context) {
        // å¯¹ç›¸åŒé”®çš„å€¼è¿›è¡Œå±€éƒ¨æ±‚å’Œ
        // "sum"é”®ï¼šå¯¹éƒ¨åˆ†æ•°å€¼æ±‚å’Œ
        // "count"é”®ï¼šå¯¹éƒ¨åˆ†è®¡æ•°æ±‚å’Œ
        // è¾“å‡º: (key, local_sum) - ä¿æŒsum/countæ ¼å¼ä¸å˜
    }
}
```

Reducer ç±» `AvgReducer`ï¼š

`AvgReducer` ç±»å¯¹æ¥è‡ª Mapper çš„è¾“å‡ºè¿›è¡Œèšåˆï¼Œè®¡ç®—æ¯ä¸ª key å¯¹åº”çš„æ€»å’Œå’Œè®¡æ•°ï¼Œæœ€ç»ˆè®¡ç®—å‡ºå¹³å‡å€¼ã€‚å®ƒå°†å¤„ç† `"sum"` å’Œ `"count"` çš„ç»“æœï¼Œå¹¶è®¡ç®—å¹³å‡å€¼ã€‚

```java
public static class AvgReducer extends Reducer<Text, LongWritable, Text, DoubleWritable> {
    long sum = 0;
    long count = 0;
    
    protected void reduce(Text key, Iterable<LongWritable> values, Context context) {
        // å¤„ç†Combineråˆå¹¶åçš„ç»“æœ
        if (key.equals("sum")) {
            for (LongWritable v : values) sum += v.get();
        } else { // count
            for (LongWritable v : values) count += v.get();
        }
    }
    
    protected void cleanup(Context context) {
        // è®¡ç®—æœ€ç»ˆå¹³å‡å€¼
        double avg = (double) sum / count;
        context.write(new Text("Average"), new DoubleWritable(avg));
    }
}
```

Job é…ç½®ï¼š

åœ¨ `main()` æ–¹æ³•ä¸­ï¼Œé…ç½® Hadoop çš„ä½œä¸šï¼Œè®¾ç½®è¾“å…¥è¾“å‡ºè·¯å¾„ã€Mapper å’Œ Reducer ç±»ï¼Œå¹¶å®šä¹‰è¾“å‡ºæ•°æ®ç±»å‹ï¼Œè¿˜åŒ…å«äº† combiner çš„è®¾ç½®ï¼Œä»¥ä¾¿ Mapper å±‚è¿›è¡Œå±€éƒ¨åˆå¹¶ã€‚

```java
public static void main(String[] args) {
    Job job = Job.getInstance(conf, "average_with_combiner");
    
    job.setMapperClass(AvgMapper.class);
    job.setCombinerClass(AvgCombiner.class);  // å…³é”®ï¼šå¯ç”¨Combiner
    job.setReducerClass(AvgReducer.class);
    
    // è¾“å‡ºç±»å‹ï¼šText, LongWritable
    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
}
```



### ï¼ˆï¼•ï¼‰`AverageWrongCombiner.java`ä»£ç ç»“æ„

åŒ…åå’Œå¯¼å…¥è¯­å¥ï¼š

ä»£ç é¦–å…ˆå¯¼å…¥äº† Hadoop å’Œç›¸å…³çš„ I/O ç±»

ä¸»ç±» `AverageWrongCombiner`ï¼š

æ•´ä¸ªç¨‹åºçš„ä¸»ç±»ï¼Œç±»åä¸º `AverageWrongCombiner`ï¼Œç”¨äºè®¡ç®—å¹³å‡å€¼ï¼Œä½†æ­¤ä»£ç ä¸­ä½¿ç”¨äº†ä¸€ä¸ªé”™è¯¯çš„ combinerã€‚

```java
public static class AvgMapper extends Mapper<LongWritable, Text, Text, LongWritable> {
    private final static Text ONEKEY = new Text("avg");
    
    protected void map(LongWritable key, Text value, Context context) {
        // è¾“å…¥æ ¼å¼: "key value"
        // è¾“å‡º: ("avg", æ•°å€¼) - æ‰€æœ‰æ•°æ®ä½¿ç”¨åŒä¸€ä¸ªé”®
    }
}
```

Mapper ç±» `AvgMapper`ï¼š

è¯¥ç±»ç»§æ‰¿è‡ª `Mapper<LongWritable, Text, Text, LongWritable>`ï¼Œè´Ÿè´£å¤„ç†è¾“å…¥æ•°æ®å¹¶ç”Ÿæˆä¸­é—´è¾“å‡ºï¼Œä¸»è¦ä»»åŠ¡æ˜¯è§£æè¾“å…¥æ•°æ®ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªå›ºå®šçš„ key-value å¯¹ï¼š`"avg"` å’Œå¯¹åº”çš„æ•°å€¼ï¼ˆ`LongWritable`ï¼‰ã€‚

`map()` æ–¹æ³•ï¼šè¯¥æ–¹æ³•è§£ææ¯è¡Œè¾“å…¥æ•°æ®ï¼Œæå–æ•°å€¼å¹¶è¾“å‡º key `"avg"` å’Œå¯¹åº”çš„ valueã€‚

```java
public static class AvgMapper extends Mapper<LongWritable, Text, Text, LongWritable> {
    private final static Text ONEKEY = new Text("avg");
    
    protected void map(LongWritable key, Text value, Context context) {
        // è¾“å…¥æ ¼å¼: "key value"
        // è¾“å‡º: ("avg", æ•°å€¼) - æ‰€æœ‰æ•°æ®ä½¿ç”¨åŒä¸€ä¸ªé”®
    }
}
```

Reducer ç±» `AvgReducer`ï¼š

`AvgReducer` ç±»ä¼šå¯¹æ¥è‡ª Mapper çš„è¾“å‡ºè¿›è¡Œèšåˆï¼Œè®¡ç®—å¹³å‡å€¼ï¼Œå®ƒå°†å¤„ç† `"avg"` çš„æ‰€æœ‰æ•°å€¼å¹¶è®¡ç®—å‡ºæœ€ç»ˆçš„å¹³å‡å€¼ã€‚

é”™è¯¯çš„ Combiner è®¾ç½®ï¼š

ä»£ç ä¸­é”™è¯¯åœ°å°† `AvgReducer` è®¾ç½®ä¸º `Combiner`ï¼Œè¿™ä¼šå¯¼è‡´ `Combiner` çš„è¡Œä¸ºä¸æ­£ç¡®ï¼ŒCombiner æœ¬åº”åœ¨ Map é˜¶æ®µæ‰§è¡Œå±€éƒ¨åˆå¹¶ï¼ˆä¾‹å¦‚æ±‚å’Œå’Œè®¡æ•°ï¼‰ï¼Œä½†æ˜¯åœ¨è¿™ä¸ªé”™è¯¯çš„å®ç°ä¸­ï¼Œ`AvgReducer` è¢«ç”¨ä½œ `Combiner`ï¼Œå®ƒè®¡ç®—çš„æ˜¯æœ€ç»ˆçš„å¹³å‡å€¼ï¼Œè€Œä¸é€‚åˆåœ¨ Map é˜¶æ®µè¿›è¡Œå±€éƒ¨åˆå¹¶ã€‚

```java
public static class WrongCombiner extends Reducer<Text, LongWritable, Text, LongWritable> {
    protected void reduce(Text key, Iterable<LongWritable> values, Context context) {
        // âŒ é”™è¯¯åšæ³•ï¼šè®¡ç®—å±€éƒ¨å¹³å‡å€¼
        long sum = 0, count = 0;
        for (LongWritable v : values) {
            sum += v.get();
            count++;
        }
        long localAvg = sum / count;   // âŒ è®¡ç®—å±€éƒ¨å¹³å‡
        // è¾“å‡º: ("avg", localAvg) - ä¼ é€’çš„æ˜¯å¹³å‡å€¼è€ŒéåŸå§‹æ•°æ®
    }
}
```

```java
public static class WrongReducer extends Reducer<Text, LongWritable, Text, DoubleWritable> {
    protected void reduce(Text key, Iterable<LongWritable> values, Context context) {
        // âŒ å¯¹å±€éƒ¨å¹³å‡å€¼å†æ±‚å¹³å‡ï¼ˆé”™ä¸ŠåŠ é”™ï¼‰
        long sum = 0, count = 0;
        for (LongWritable v : values) {
            sum += v.get();  // è¿™é‡Œå¾—åˆ°çš„æ˜¯å„ä¸ªCombinerè¾“å‡ºçš„å±€éƒ¨å¹³å‡å€¼
            count++;
        }
        double wrongFinalAvg = (double) sum / count;
        // è¾“å‡º: ("WrongAverage", é”™è¯¯ç»“æœ)
    }
}
```

Job é…ç½®ï¼š

åœ¨ `main()` æ–¹æ³•ä¸­ï¼Œé…ç½® Hadoop çš„ä½œä¸šï¼Œè®¾ç½®è¾“å…¥è¾“å‡ºè·¯å¾„ã€Mapper å’Œ Reducer ç±»ï¼Œå¹¶å®šä¹‰è¾“å‡ºæ•°æ®ç±»å‹ã€‚è¿™éƒ¨åˆ†é…ç½®ä¸æ ‡å‡†çš„ MapReduce ä½œä¸šé…ç½®ç›¸åŒï¼Œä½†ä½¿ç”¨äº†ä¸é€‚å½“çš„ `Combiner` è®¾ç½®ã€‚

```java
public static void main(String[] args) {
    Job job = Job.getInstance(conf, "average_wrong_combiner");
    
    job.setMapperClass(AvgMapper.class);
    job.setCombinerClass(WrongCombiner.class);   // âŒ ä½¿ç”¨é”™è¯¯çš„Combiner
    job.setReducerClass(WrongReducer.class);
    
    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
}
```

## 3.å®éªŒæ­¥éª¤

### 3.1é›†ç¾¤ä¸è¿è¡Œç¯å¢ƒåˆå§‹åŒ–

è§1.3

### 3.2ä¸Šä¼ æ•°æ®å’Œä»£ç 

**1.å‡†å¤‡å¥½æ•°æ®å¹¶ä¸Šä¼ è‡³HDFS**

ä¸Šä¼ pythonè„šæœ¬æ–‡ä»¶ã€ç”Ÿæˆæ•°æ®é›†ã€ä¸Šä¼ æ•°æ®é›†è‡³HDFS



**2.ä¸Šä¼ ä»£ç **

æœ¬åœ°å†™å¥½Javaä»£ç åå°†javaæ–‡ä»¶ä¸Šä¼ åˆ°èŠ‚ç‚¹



**3.å¹¶ä½¿ç”¨Hadoopçš„classç¼–è¯‘**

**4.åœ¨Linuxä¸Šæ‰“åŒ…æˆjar**

### 3.3è¿›è¡Œå®éªŒ

**1.æ¯ä¸ªèŠ‚ç‚¹åˆ†åˆ«åœ¨ä¸åŒæ•°æ®é›†æ‰§è¡Œä»»åŠ¡ï¼Œä¾æ¬¡è¿è¡Œæœ‰/æ— combinerçš„å®éªŒ**

è¿è¡Œä¹‹å‰éœ€è¦ç¡®è®¤è‡ªå·±çš„è¾“å‡ºç›®å½•ä¸ºç©º



è¿è¡Œç»“æŸåï¼Œå¯åœ¨æ§åˆ¶å°ç¡®è®¤ä½œä¸šæ˜¯å¦æˆåŠŸï¼Œå¦‚å›¾å‡ºç°

- `map 100% reduce 100%`
- `Job job_xxx completed successfully`
  å³ä¸ºæˆåŠŸ

![é¡¹ç›®æˆªå›¾](https://github.com/LornaLiang/DasebigdataAssignmentGroup32/blob/15e862c22e1701975e751523d81eb98b85aa6bd3/image/yqr_img/real2.png)

**2.å®éªŒæˆåŠŸååœ¨Web UIä¸­æŸ¥çœ‹ä½œä¸šè¯¦æƒ…å¹¶è®°å½•æ•°æ®**

Web Uiç•Œé¢ä¸­YARN ResourceManager UIå¯æ€»è§ˆæ‰€æœ‰YARNä»»åŠ¡

![é¡¹ç›®æˆªå›¾](https://github.com/LornaLiang/DasebigdataAssignmentGroup32/blob/cdf132d76716b60df7ef34130b9a047e301f4262/image/yqr_img/application.png)

MapReduce Job History UIèƒ½å¤Ÿçœ‹åˆ°å·²ç»å®Œæˆçš„ MapReduce Jobï¼Œå¹¶ä¸”èƒ½å¤Ÿè·å–æ›´ç»†è‡´çš„æƒ…å†µ

![é¡¹ç›®æˆªå›¾](https://github.com/LornaLiang/DasebigdataAssignmentGroup32/blob/cdf132d76716b60df7ef34130b9a047e301f4262/image/yqr_img/jobhistory.png)

å¦‚å›¾æ‰€ç¤ºï¼Œåœ¨MapReduce Jobçš„Overviewç•Œé¢æŸ¥çœ‹MapReduceçš„æ‰§è¡Œæ—¶é—´

![é¡¹ç›®æˆªå›¾](https://github.com/LornaLiang/DasebigdataAssignmentGroup32/blob/15e862c22e1701975e751523d81eb98b85aa6bd3/image/yqr_img/uniform_noc/1.png)

å¦‚å›¾æ‰€ç¤ºï¼Œä»¥Mapçš„countersä¸ºä¾‹ï¼Œå¯ä»¥è®°å½•æœ¬æ¬¡å®éªŒçš„å…³é”®æŒ‡æ ‡ï¼Œå¦‚ï¼š

- Map Output Records
- Map Output Bytes
- Map Output Materialized Bytes
  ç­‰

Reduceçš„æ•°æ®åŒç†

![é¡¹ç›®æˆªå›¾](https://github.com/LornaLiang/DasebigdataAssignmentGroup32/blob/15e862c22e1701975e751523d81eb98b85aa6bd3/image/yqr_img/uniform_noc/mapcounters1.png)

### 3.3å®éªŒæ•°æ®æ•´ç†ä¸å¯¼å‡º

å„ç»„å‘˜å°†æ•°æ®æ±‡é›†åˆ°è¡¨æ ¼ä¸­ï¼Œæ–¹ä¾¿è¿›è¡Œåç»­çš„å›¾è¡¨ç»˜åˆ¶ä¸æ•°æ®åˆ†æ

>>>>>>> Stashed changes
