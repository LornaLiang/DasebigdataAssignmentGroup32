```
#设置各节点名称
sudo hostnamectl set-hostname worker1
#设置完成重新打开SSH会话

#配置/etc/hosts
sudo nano /etc/hosts
#加入以下内容
172.16.3.45 master
172.16.3.46 worker1
172.16.3.47 worker2
172.16.3.48 worker3

#验证是否生效
ping -c 2 master
ping -c 2 worker1
ping -c 2 worker2
ping -c 2 worker3

#创建Hadoop用户
sudo adduser hadoop
#把Hadoop用户加入sudo权限
sudo usermod -aG sudo hadoop

#关闭防火墙
ufw disable
ufw status

#设置免密登录（仅master）

#切换回root安装java
sudo apt update
sudo apt install -y openjdk-8-jdk

#切换回Hadoop安装Hadoop（master安装完分发至各节点）
#我们使用清华镜像
su - hadoop
cd /home/hadoop
wget https://downloads.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz
tar -xzf hadoop-3.3.6.tar.gz
mv hadoop-3.3.6 hadoop

#配置环境变量
配置环境变量（~/.bashrc）
配置 core-site.xml
配置 hdfs-site.xml
配置 yarn-site.xml

#分发
scp -r hadoop worker1:/home/hadoop/
scp -r hadoop worker2:/home/hadoop/
scp -r hadoop worker3:/home/hadoop/

#格式化NameNode
hdfs namenode -format

#启动HDFS和YARN
start-dfs.sh
start-yarn.sh

#检查进程
jps

```

所有后续操作必须在hadoop用户（启动或停止hadoop、提交mapreduce任务、HDFS操作、上传数据运行实验、yarn查看任务等）


部署流程
1. 创建 hadoop 用户
2. 关闭防火墙
3. 设置 SSH 免密登录（只在master做，master → workers）
  ---------------（分界线）---------------
4. 安装 Java（4 台 root用户）
5. 安装 Hadoop（在master安装，master → 分发到 workers）
6. 格式化 HDFS（master）
7. 启动 HDFS 和 YARN
8. 所有后续操作必须在hadoop用户

