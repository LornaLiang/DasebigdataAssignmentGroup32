##  数据形式（key，value）

**1.**均匀（数据集大小100M）

**2.**中度倾斜 60%来自同一个key（100M）

**3.**极端倾斜 99%来自同一个hot-key（100M）

**4.**极端倾斜99%来自同一个hot-key（200M）

**5**.均匀（数据集大小50M）

**6**.均匀（数据集大小25M）

**7.**中度倾斜 60%来自同一个key（50M）

**8.**中度倾斜 60%来自同一个key（25M）

#### 数据集已上传至hdfs

```
#文件名
1.uniform_100MB
2.skew60_100MB
3.extreme90_100MB
4.extreme90_200MB
5.uniform_50MB
6.uniform_25MB
7.skew_50MB
8.skew_25MB

#文件位置(hdfs)
/data

#查看hdfs中的文件文件命令
hdfs dfs -ls -R
```



## 任务

**（1）**在数据集1 上进行“按key 求和”的操作（有combiner+无combiner）

**（2）**在数据集2上进行“按key 求和”的操作（有combiner+无combiner）

**（3）**在数据集3 上进行“按key 求和”的操作（有combiner+无combiner）

**（4）**在数据集4 上进行“按key 求和”的操作（有combiner+无combiner）

**（5）**在数据集5上进行“按key 求和”的操作（有combiner+无combiner）

**（6）**在数据集6上进行“按key 求和”的操作（有combiner+无combiner）

**（7）**在数据集7上进行“按key 求和”的操作（有combiner+无combiner）

**（8）**在数据集8上进行“按key 求和”的操作（有combiner+无combiner）

**（！）**在数据集1 上进行 “求平均值”的操作（有combiner+无combiner，该任务不适合使用combiner，所以combiner会失败）



### 任务执行（必须确保是hadoop用户，参见上一个文件）

（1）在 本地写 Java 代码（用 VS Code / IDEA / Notepad++ 都行）

（2）把 `.java` 文件上传到节点（上传文件和之前上传测试文件的命令一致）

```
##在节点创建目录
mkdir -p ~/mr_avg ##mr_avg文件名自己定 
cd ~/mr_avg

##新建会话，协议选择sftp，输入公网ip，用户名hadoop，密码123456

##进入创建好的文件
cd mr_avg

##依次把.java拖进去

##上传完检查 
ls -l
输出类似：
-rw-rw-r--    1 hadoop   hadoop       3726 Nov 26 16:02 AverageWithCombiner.java
权限必须是hadoop

```

（3）使用 Hadoop 的 classpath 编译

```
##依次执行，把所有的java编译
javac -classpath `hadoop classpath` -d . AverageNoCombiner.java##AverageNoCombiner.java是你的java文件名


##都打包完以后查看class文件
ls -l | grep class

##每个class都要包含：
-rw-rw-r-- 1 hadoop hadoop 1723 Nov 26 16:07 AverageNoCombiner$AvgMapper.class
-rw-rw-r-- 1 hadoop hadoop 2331 Nov 26 16:07 AverageNoCombiner$AvgReducer.class
-rw-rw-r-- 1 hadoop hadoop 1476 Nov 26 16:07 AverageNoCombiner.class

```

（4）在 Linux 上打包成 jar

```
##依次打包
jar -cvf avg_no_combiner.jar AverageNoCombiner*.class
jar -cvf sum_no_combiner.jar SumNoCombiner*.class
jar -cvf sum_with_combiner.jar SumWithCombiner*.class


##查看结果
ls -l | grep jar

#结果长这样：
-rw-rw-r-- 1 hadoop hadoop 3204 Nov 26 16:09 avg_no_combiner.jar

```

(5)运行之前确认自己的输出目录必须为空，每次的输出目录必须不同

```
##如果测试过那将测试目录删除，如果没测试那不用管
hdfs dfs -rm -r -f /output_cll ###output_XX 修改成你自己测试时的输出目录
```

（5）在 Hadoop 集群上运行 MapReduce

```
##修改你需要的数据集名字，修改你的输出目录
hadoop jar avg_no_combiner.jar AverageNoCombiner /data/uniform_100MB.txt /output_LN_noC


hadoop jar sum_no_combiner.jar SumNoCombiner /data/extreme90_200MB.txt /output_LN_noC_e90
hadoop jar sum_with_combiner.jar SumWithCombiner /data/extreme90_200MB.txt /output_LN_C_e90

hadoop jar sum_no_combiner.jar SumNoCombiner /data/skew60_25MB.txt /output_LN_noC_s60
hadoop jar sum_with_combiner.jar SumWithCombiner /data/skew60_25MB.txt /output_LN_C_s60

hadoop jar avg_no_combiner.jar AverageNoCombiner /data/avg_50MB.txt /output_LN_avg_noC
hadoop jar avg_wrong_combiner.jar AverageWrongCombiner /data/avg_50MB.txt /output_LN_avg_wrC
hadoop jar avg_with_combiner.jar AverageWithCombiner /data/avg_50MB.txt /output_LN_avg_wiC


查看输出文件：
hdfs dfs -cat /output_LN_avg_noC/part-r-00000
hdfs dfs -cat /output_LN_avg_wrC/part-r-00000
hdfs dfs -cat /output_LN_avg_wiC/part-r-00000
```

（6）在Web UI 端口 8088 / 19888 分析 job 进行截图

```
http://121.41.113.71:8088/cluster
http://121.41.113.71:19888/jobhistory
```







根据实验环境2核2GB选择100M数据是合理的，hadoop默认block size 大小是128M且combiner的作用与数据量大小无关，和key的局部聚合率有关。

